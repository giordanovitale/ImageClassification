{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Loading dependencies"
      ],
      "metadata": {
        "id": "OzF8_EWZjWe7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "os.chdir(\"/content/drive/MyDrive/MachineLearningProject\")\n",
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/MachineLearningProject\")\n",
        "from helper_functions import scheduler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuWfxZfejYVm",
        "outputId": "40eb7a16-092c-48dc-be8a-b94d12b44e7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the models"
      ],
      "metadata": {
        "id": "gZej2nhAjaE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run resnet.py"
      ],
      "metadata": {
        "id": "vDA8Hjk3jh61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the data"
      ],
      "metadata": {
        "id": "cZSsr_24jlOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\"/content/drive/MyDrive/MachineLearningProject/data/train\",\n",
        "                                                       label_mode=\"binary\",\n",
        "                                                       color_mode=\"rgb\",\n",
        "                                                       batch_size=32,\n",
        "                                                       image_size=(224, 224),\n",
        "                                                       shuffle=True,\n",
        "                                                       seed=42)\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\"/content/drive/MyDrive/MachineLearningProject/data/test\",\n",
        "                                                     label_mode=\"binary\",\n",
        "                                                     color_mode=\"rgb\",\n",
        "                                                     batch_size=32,\n",
        "                                                     image_size=(224, 224),\n",
        "                                                     shuffle=True,\n",
        "                                                     seed=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaBBq4Hcjoax",
        "outputId": "de0b587e-9681-4149-b44e-7b7b8f8e74b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4743 files belonging to 2 classes.\n",
            "Found 1184 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet14"
      ],
      "metadata": {
        "id": "b0z218uujo7d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the model"
      ],
      "metadata": {
        "id": "M7qpjoUpjsdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res_14 = tf.keras.models.load_model(\n",
        "    \"/content/drive/MyDrive/MachineLearningProject/models/resnet/res_14.keras\",\n",
        "    safe_mode=False)\n",
        "\n",
        "res_14.summary()"
      ],
      "metadata": {
        "id": "6IaPAIGojuB_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7d25c45-aea6-4f49-d478-59b1aa60b1e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"ResNet14\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " Input (InputLayer)          [(32, 224, 224, 3)]          0         []                            \n",
            "                                                                                                  \n",
            " Random_horizontal_flip (Ra  (32, 224, 224, 3)            0         ['Input[0][0]']               \n",
            " ndomFlip)                                                                                        \n",
            "                                                                                                  \n",
            " Random_contrast (RandomCon  (32, 224, 224, 3)            0         ['Random_horizontal_flip[0][0]\n",
            " trast)                                                             ']                            \n",
            "                                                                                                  \n",
            " Per_image_standardisation   (32, 224, 224, 3)            0         ['Random_contrast[0][0]']     \n",
            " (Lambda)                                                                                         \n",
            "                                                                                                  \n",
            " ZeroPadding (ZeroPadding2D  (32, 230, 230, 3)            0         ['Per_image_standardisation[0]\n",
            " )                                                                  [0]']                         \n",
            "                                                                                                  \n",
            " Conv1 (Conv2D)              (32, 112, 112, 64)           9472      ['ZeroPadding[0][0]']         \n",
            "                                                                                                  \n",
            " BatchNorm1 (BatchNormaliza  (32, 112, 112, 64)           256       ['Conv1[0][0]']               \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " ReLU1 (ReLU)                (32, 112, 112, 64)           0         ['BatchNorm1[0][0]']          \n",
            "                                                                                                  \n",
            " MaxPool (MaxPooling2D)      (32, 56, 56, 64)             0         ['ReLU1[0][0]']               \n",
            "                                                                                                  \n",
            " Conv1_1 (Conv2D)            (32, 56, 56, 64)             36928     ['MaxPool[0][0]']             \n",
            "                                                                                                  \n",
            " BatchNorm1_1 (BatchNormali  (32, 56, 56, 64)             256       ['Conv1_1[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " ReLU1_1 (ReLU)              (32, 56, 56, 64)             0         ['BatchNorm1_1[0][0]']        \n",
            "                                                                                                  \n",
            " Conv2_1 (Conv2D)            (32, 56, 56, 64)             36928     ['ReLU1_1[0][0]']             \n",
            "                                                                                                  \n",
            " BatchNorm2_1 (BatchNormali  (32, 56, 56, 64)             256       ['Conv2_1[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " ReLU2_1 (ReLU)              (32, 56, 56, 64)             0         ['BatchNorm2_1[0][0]']        \n",
            "                                                                                                  \n",
            " SkipConnection_1 (Add)      (32, 56, 56, 64)             0         ['ReLU2_1[0][0]',             \n",
            "                                                                     'MaxPool[0][0]']             \n",
            "                                                                                                  \n",
            " ReLU3_1 (ReLU)              (32, 56, 56, 64)             0         ['SkipConnection_1[0][0]']    \n",
            "                                                                                                  \n",
            " Conv1_2 (Conv2D)            (32, 56, 56, 64)             36928     ['ReLU3_1[0][0]']             \n",
            "                                                                                                  \n",
            " BatchNorm1_2 (BatchNormali  (32, 56, 56, 64)             256       ['Conv1_2[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " ReLU1_2 (ReLU)              (32, 56, 56, 64)             0         ['BatchNorm1_2[0][0]']        \n",
            "                                                                                                  \n",
            " Conv2_2 (Conv2D)            (32, 56, 56, 64)             36928     ['ReLU1_2[0][0]']             \n",
            "                                                                                                  \n",
            " BatchNorm2_2 (BatchNormali  (32, 56, 56, 64)             256       ['Conv2_2[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " ReLU2_2 (ReLU)              (32, 56, 56, 64)             0         ['BatchNorm2_2[0][0]']        \n",
            "                                                                                                  \n",
            " SkipConnection_2 (Add)      (32, 56, 56, 64)             0         ['ReLU2_2[0][0]',             \n",
            "                                                                     'ReLU3_1[0][0]']             \n",
            "                                                                                                  \n",
            " ReLU3_2 (ReLU)              (32, 56, 56, 64)             0         ['SkipConnection_2[0][0]']    \n",
            "                                                                                                  \n",
            " Conv1_3 (Conv2D)            (32, 28, 28, 128)            73856     ['ReLU3_2[0][0]']             \n",
            "                                                                                                  \n",
            " BatchNorm1_3 (BatchNormali  (32, 28, 28, 128)            512       ['Conv1_3[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " ReLU1_3 (ReLU)              (32, 28, 28, 128)            0         ['BatchNorm1_3[0][0]']        \n",
            "                                                                                                  \n",
            " Conv2_3 (Conv2D)            (32, 28, 28, 128)            147584    ['ReLU1_3[0][0]']             \n",
            "                                                                                                  \n",
            " BatchNorm2_3 (BatchNormali  (32, 28, 28, 128)            512       ['Conv2_3[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " Conv3_3 (Conv2D)            (32, 28, 28, 128)            8320      ['ReLU3_2[0][0]']             \n",
            "                                                                                                  \n",
            " ReLU2_3 (ReLU)              (32, 28, 28, 128)            0         ['BatchNorm2_3[0][0]']        \n",
            "                                                                                                  \n",
            " BatchNorm3_3 (BatchNormali  (32, 28, 28, 128)            512       ['Conv3_3[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " SkipConnection_3 (Add)      (32, 28, 28, 128)            0         ['ReLU2_3[0][0]',             \n",
            "                                                                     'BatchNorm3_3[0][0]']        \n",
            "                                                                                                  \n",
            " ReLU3_3 (ReLU)              (32, 28, 28, 128)            0         ['SkipConnection_3[0][0]']    \n",
            "                                                                                                  \n",
            " Conv1_4 (Conv2D)            (32, 28, 28, 128)            147584    ['ReLU3_3[0][0]']             \n",
            "                                                                                                  \n",
            " BatchNorm1_4 (BatchNormali  (32, 28, 28, 128)            512       ['Conv1_4[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " ReLU1_4 (ReLU)              (32, 28, 28, 128)            0         ['BatchNorm1_4[0][0]']        \n",
            "                                                                                                  \n",
            " Conv2_4 (Conv2D)            (32, 28, 28, 128)            147584    ['ReLU1_4[0][0]']             \n",
            "                                                                                                  \n",
            " BatchNorm2_4 (BatchNormali  (32, 28, 28, 128)            512       ['Conv2_4[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " ReLU2_4 (ReLU)              (32, 28, 28, 128)            0         ['BatchNorm2_4[0][0]']        \n",
            "                                                                                                  \n",
            " SkipConnection_4 (Add)      (32, 28, 28, 128)            0         ['ReLU2_4[0][0]',             \n",
            "                                                                     'ReLU3_3[0][0]']             \n",
            "                                                                                                  \n",
            " ReLU3_4 (ReLU)              (32, 28, 28, 128)            0         ['SkipConnection_4[0][0]']    \n",
            "                                                                                                  \n",
            " Conv1_5 (Conv2D)            (32, 14, 14, 256)            295168    ['ReLU3_4[0][0]']             \n",
            "                                                                                                  \n",
            " BatchNorm1_5 (BatchNormali  (32, 14, 14, 256)            1024      ['Conv1_5[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " ReLU1_5 (ReLU)              (32, 14, 14, 256)            0         ['BatchNorm1_5[0][0]']        \n",
            "                                                                                                  \n",
            " Conv2_5 (Conv2D)            (32, 14, 14, 256)            590080    ['ReLU1_5[0][0]']             \n",
            "                                                                                                  \n",
            " BatchNorm2_5 (BatchNormali  (32, 14, 14, 256)            1024      ['Conv2_5[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " Conv3_5 (Conv2D)            (32, 14, 14, 256)            33024     ['ReLU3_4[0][0]']             \n",
            "                                                                                                  \n",
            " ReLU2_5 (ReLU)              (32, 14, 14, 256)            0         ['BatchNorm2_5[0][0]']        \n",
            "                                                                                                  \n",
            " BatchNorm3_5 (BatchNormali  (32, 14, 14, 256)            1024      ['Conv3_5[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " SkipConnection_5 (Add)      (32, 14, 14, 256)            0         ['ReLU2_5[0][0]',             \n",
            "                                                                     'BatchNorm3_5[0][0]']        \n",
            "                                                                                                  \n",
            " ReLU3_5 (ReLU)              (32, 14, 14, 256)            0         ['SkipConnection_5[0][0]']    \n",
            "                                                                                                  \n",
            " Conv1_6 (Conv2D)            (32, 14, 14, 256)            590080    ['ReLU3_5[0][0]']             \n",
            "                                                                                                  \n",
            " BatchNorm1_6 (BatchNormali  (32, 14, 14, 256)            1024      ['Conv1_6[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " ReLU1_6 (ReLU)              (32, 14, 14, 256)            0         ['BatchNorm1_6[0][0]']        \n",
            "                                                                                                  \n",
            " Conv2_6 (Conv2D)            (32, 14, 14, 256)            590080    ['ReLU1_6[0][0]']             \n",
            "                                                                                                  \n",
            " BatchNorm2_6 (BatchNormali  (32, 14, 14, 256)            1024      ['Conv2_6[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " ReLU2_6 (ReLU)              (32, 14, 14, 256)            0         ['BatchNorm2_6[0][0]']        \n",
            "                                                                                                  \n",
            " SkipConnection_6 (Add)      (32, 14, 14, 256)            0         ['ReLU2_6[0][0]',             \n",
            "                                                                     'ReLU3_5[0][0]']             \n",
            "                                                                                                  \n",
            " ReLU3_6 (ReLU)              (32, 14, 14, 256)            0         ['SkipConnection_6[0][0]']    \n",
            "                                                                                                  \n",
            " GlobalAvgPooling (GlobalAv  (32, 256)                    0         ['ReLU3_6[0][0]']             \n",
            " eragePooling2D)                                                                                  \n",
            "                                                                                                  \n",
            " Output (Dense)              (32, 1)                      257       ['GlobalAvgPooling[0][0]']    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2789761 (10.64 MB)\n",
            "Trainable params: 2785281 (10.63 MB)\n",
            "Non-trainable params: 4480 (17.50 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compiling the model"
      ],
      "metadata": {
        "id": "KhE8T6lzj4iH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res_14.compile(loss=\"binary_crossentropy\",\n",
        "               optimizer=Adam(),\n",
        "               metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "agzkhaGuj6Wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Creating Callbacks"
      ],
      "metadata": {
        "id": "_gQ_7cchj_7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res_14_checkpoint = ModelCheckpoint(\n",
        "    filepath=\"/content/drive/MyDrive/MachineLearningProject/model_weights/resnet/res_14.keras\",\n",
        "    save_weights_only=True,\n",
        "    save_best_only=False)\n",
        "\n",
        "res_14_csv_logger = CSVLogger('/content/drive/MyDrive/MachineLearningProject/histories/resnet/res_14.log')"
      ],
      "metadata": {
        "id": "3X2EVCF-kB8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fitting the model"
      ],
      "metadata": {
        "id": "L7Nwr0UekJxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res_14_history = res_14.fit(train_ds,\n",
        "                            epochs=300,\n",
        "                            steps_per_epoch=len(train_ds),\n",
        "                            validation_data=val_ds,\n",
        "                            validation_steps=len(val_ds),\n",
        "                            callbacks=[res_14_checkpoint, res_14_csv_logger])"
      ],
      "metadata": {
        "id": "pEVf4c22kLlK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6d26278-e602-4c24-de86-5e99700e7701"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "149/149 [==============================] - 271s 1s/step - loss: 0.4237 - accuracy: 0.8151 - val_loss: 0.5415 - val_accuracy: 0.8429\n",
            "Epoch 2/300\n",
            "149/149 [==============================] - 16s 101ms/step - loss: 0.3240 - accuracy: 0.8659 - val_loss: 0.3496 - val_accuracy: 0.8623\n",
            "Epoch 3/300\n",
            "149/149 [==============================] - 15s 100ms/step - loss: 0.2792 - accuracy: 0.8832 - val_loss: 0.2641 - val_accuracy: 0.8910\n",
            "Epoch 4/300\n",
            "149/149 [==============================] - 16s 101ms/step - loss: 0.2491 - accuracy: 0.9007 - val_loss: 0.3059 - val_accuracy: 0.8784\n",
            "Epoch 5/300\n",
            "149/149 [==============================] - 16s 101ms/step - loss: 0.2234 - accuracy: 0.9096 - val_loss: 0.3353 - val_accuracy: 0.8530\n",
            "Epoch 6/300\n",
            "149/149 [==============================] - 15s 100ms/step - loss: 0.1985 - accuracy: 0.9239 - val_loss: 0.4473 - val_accuracy: 0.8091\n",
            "Epoch 7/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.1864 - accuracy: 0.9281 - val_loss: 0.3944 - val_accuracy: 0.8514\n",
            "Epoch 8/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.1701 - accuracy: 0.9321 - val_loss: 0.4137 - val_accuracy: 0.8480\n",
            "Epoch 9/300\n",
            "149/149 [==============================] - 16s 100ms/step - loss: 0.1504 - accuracy: 0.9408 - val_loss: 0.4813 - val_accuracy: 0.8463\n",
            "Epoch 10/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.1514 - accuracy: 0.9397 - val_loss: 0.1859 - val_accuracy: 0.9282\n",
            "Epoch 11/300\n",
            "149/149 [==============================] - 15s 100ms/step - loss: 0.1294 - accuracy: 0.9490 - val_loss: 0.2884 - val_accuracy: 0.9012\n",
            "Epoch 12/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.1271 - accuracy: 0.9505 - val_loss: 0.6638 - val_accuracy: 0.7939\n",
            "Epoch 13/300\n",
            "149/149 [==============================] - 16s 101ms/step - loss: 0.1153 - accuracy: 0.9551 - val_loss: 0.4128 - val_accuracy: 0.8260\n",
            "Epoch 14/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.1119 - accuracy: 0.9585 - val_loss: 0.1686 - val_accuracy: 0.9316\n",
            "Epoch 15/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0975 - accuracy: 0.9606 - val_loss: 0.1838 - val_accuracy: 0.9316\n",
            "Epoch 16/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.1097 - accuracy: 0.9583 - val_loss: 0.2253 - val_accuracy: 0.9198\n",
            "Epoch 17/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0868 - accuracy: 0.9652 - val_loss: 0.1927 - val_accuracy: 0.9299\n",
            "Epoch 18/300\n",
            "149/149 [==============================] - 15s 100ms/step - loss: 0.0871 - accuracy: 0.9652 - val_loss: 0.1484 - val_accuracy: 0.9434\n",
            "Epoch 19/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0709 - accuracy: 0.9739 - val_loss: 0.1373 - val_accuracy: 0.9493\n",
            "Epoch 20/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0994 - accuracy: 0.9627 - val_loss: 0.2358 - val_accuracy: 0.9181\n",
            "Epoch 21/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0701 - accuracy: 0.9755 - val_loss: 0.1343 - val_accuracy: 0.9443\n",
            "Epoch 22/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0523 - accuracy: 0.9802 - val_loss: 0.2871 - val_accuracy: 0.9079\n",
            "Epoch 23/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0603 - accuracy: 0.9768 - val_loss: 0.2148 - val_accuracy: 0.9181\n",
            "Epoch 24/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0605 - accuracy: 0.9760 - val_loss: 0.3907 - val_accuracy: 0.9096\n",
            "Epoch 25/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0504 - accuracy: 0.9808 - val_loss: 0.3176 - val_accuracy: 0.8995\n",
            "Epoch 26/300\n",
            "149/149 [==============================] - 16s 101ms/step - loss: 0.0367 - accuracy: 0.9873 - val_loss: 0.1203 - val_accuracy: 0.9569\n",
            "Epoch 27/300\n",
            "149/149 [==============================] - 15s 100ms/step - loss: 0.0427 - accuracy: 0.9850 - val_loss: 0.6224 - val_accuracy: 0.8615\n",
            "Epoch 28/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0332 - accuracy: 0.9876 - val_loss: 0.2411 - val_accuracy: 0.9274\n",
            "Epoch 29/300\n",
            "149/149 [==============================] - 16s 101ms/step - loss: 0.0398 - accuracy: 0.9850 - val_loss: 0.1655 - val_accuracy: 0.9485\n",
            "Epoch 30/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0332 - accuracy: 0.9884 - val_loss: 0.1662 - val_accuracy: 0.9434\n",
            "Epoch 31/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0333 - accuracy: 0.9878 - val_loss: 0.2437 - val_accuracy: 0.9274\n",
            "Epoch 32/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0292 - accuracy: 0.9882 - val_loss: 0.2342 - val_accuracy: 0.9291\n",
            "Epoch 33/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0302 - accuracy: 0.9871 - val_loss: 0.1195 - val_accuracy: 0.9527\n",
            "Epoch 34/300\n",
            "149/149 [==============================] - 16s 100ms/step - loss: 0.0270 - accuracy: 0.9918 - val_loss: 0.2551 - val_accuracy: 0.9130\n",
            "Epoch 35/300\n",
            "149/149 [==============================] - 16s 101ms/step - loss: 0.0492 - accuracy: 0.9814 - val_loss: 0.2411 - val_accuracy: 0.9147\n",
            "Epoch 36/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0369 - accuracy: 0.9859 - val_loss: 0.1535 - val_accuracy: 0.9561\n",
            "Epoch 37/300\n",
            "149/149 [==============================] - 16s 101ms/step - loss: 0.0155 - accuracy: 0.9945 - val_loss: 0.1628 - val_accuracy: 0.9451\n",
            "Epoch 38/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0091 - accuracy: 0.9977 - val_loss: 0.4959 - val_accuracy: 0.8877\n",
            "Epoch 39/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0189 - accuracy: 0.9939 - val_loss: 0.1264 - val_accuracy: 0.9611\n",
            "Epoch 40/300\n",
            "149/149 [==============================] - 16s 100ms/step - loss: 0.0201 - accuracy: 0.9947 - val_loss: 0.1591 - val_accuracy: 0.9510\n",
            "Epoch 41/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0332 - accuracy: 0.9876 - val_loss: 1.0270 - val_accuracy: 0.7880\n",
            "Epoch 42/300\n",
            "149/149 [==============================] - 16s 100ms/step - loss: 0.0347 - accuracy: 0.9886 - val_loss: 0.1242 - val_accuracy: 0.9611\n",
            "Epoch 43/300\n",
            "149/149 [==============================] - 16s 101ms/step - loss: 0.0323 - accuracy: 0.9899 - val_loss: 0.5821 - val_accuracy: 0.8361\n",
            "Epoch 44/300\n",
            "149/149 [==============================] - 16s 100ms/step - loss: 0.0229 - accuracy: 0.9914 - val_loss: 0.2015 - val_accuracy: 0.9392\n",
            "Epoch 45/300\n",
            "149/149 [==============================] - 16s 100ms/step - loss: 0.0131 - accuracy: 0.9947 - val_loss: 0.1412 - val_accuracy: 0.9586\n",
            "Epoch 46/300\n",
            "149/149 [==============================] - 16s 101ms/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.3122 - val_accuracy: 0.9122\n",
            "Epoch 47/300\n",
            "149/149 [==============================] - 15s 100ms/step - loss: 0.0187 - accuracy: 0.9937 - val_loss: 0.1784 - val_accuracy: 0.9485\n",
            "Epoch 48/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0145 - accuracy: 0.9949 - val_loss: 0.1814 - val_accuracy: 0.9502\n",
            "Epoch 49/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0127 - accuracy: 0.9947 - val_loss: 0.3013 - val_accuracy: 0.9400\n",
            "Epoch 50/300\n",
            "149/149 [==============================] - 15s 100ms/step - loss: 0.0293 - accuracy: 0.9897 - val_loss: 0.2234 - val_accuracy: 0.9350\n",
            "Epoch 51/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 0.1900 - val_accuracy: 0.9510\n",
            "Epoch 52/300\n",
            "149/149 [==============================] - 16s 100ms/step - loss: 0.0122 - accuracy: 0.9956 - val_loss: 0.1241 - val_accuracy: 0.9654\n",
            "Epoch 53/300\n",
            "149/149 [==============================] - 15s 100ms/step - loss: 0.0104 - accuracy: 0.9975 - val_loss: 0.1715 - val_accuracy: 0.9459\n",
            "Epoch 54/300\n",
            "149/149 [==============================] - 16s 101ms/step - loss: 0.0200 - accuracy: 0.9935 - val_loss: 0.1997 - val_accuracy: 0.9451\n",
            "Epoch 55/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0189 - accuracy: 0.9937 - val_loss: 0.2700 - val_accuracy: 0.9079\n",
            "Epoch 56/300\n",
            "149/149 [==============================] - 16s 100ms/step - loss: 0.0179 - accuracy: 0.9937 - val_loss: 0.1237 - val_accuracy: 0.9679\n",
            "Epoch 57/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0126 - accuracy: 0.9962 - val_loss: 0.1967 - val_accuracy: 0.9519\n",
            "Epoch 58/300\n",
            "149/149 [==============================] - 15s 100ms/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.1898 - val_accuracy: 0.9544\n",
            "Epoch 59/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0069 - accuracy: 0.9975 - val_loss: 0.2709 - val_accuracy: 0.9333\n",
            "Epoch 60/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0288 - accuracy: 0.9888 - val_loss: 0.1494 - val_accuracy: 0.9586\n",
            "Epoch 61/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.2194 - val_accuracy: 0.9502\n",
            "Epoch 62/300\n",
            "149/149 [==============================] - 16s 100ms/step - loss: 0.0178 - accuracy: 0.9945 - val_loss: 0.1848 - val_accuracy: 0.9519\n",
            "Epoch 63/300\n",
            "149/149 [==============================] - 15s 100ms/step - loss: 0.0121 - accuracy: 0.9962 - val_loss: 0.3979 - val_accuracy: 0.9096\n",
            "Epoch 64/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 0.1952 - val_accuracy: 0.9417\n",
            "Epoch 65/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0612 - accuracy: 0.9783 - val_loss: 0.1553 - val_accuracy: 0.9603\n",
            "Epoch 66/300\n",
            "149/149 [==============================] - 16s 102ms/step - loss: 0.0086 - accuracy: 0.9977 - val_loss: 0.2529 - val_accuracy: 0.9231\n",
            "Epoch 67/300\n",
            "149/149 [==============================] - 16s 99ms/step - loss: 0.0077 - accuracy: 0.9975 - val_loss: 0.1507 - val_accuracy: 0.9578\n",
            "Epoch 68/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.1456 - val_accuracy: 0.9637\n",
            "Epoch 69/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.1571 - val_accuracy: 0.9628\n",
            "Epoch 70/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 8.9763e-04 - accuracy: 1.0000 - val_loss: 0.1583 - val_accuracy: 0.9578\n",
            "Epoch 71/300\n",
            "149/149 [==============================] - 15s 100ms/step - loss: 0.0039 - accuracy: 0.9985 - val_loss: 0.1758 - val_accuracy: 0.9569\n",
            "Epoch 72/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 0.2476 - val_accuracy: 0.9544\n",
            "Epoch 73/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0251 - accuracy: 0.9903 - val_loss: 0.2868 - val_accuracy: 0.9459\n",
            "Epoch 74/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0141 - accuracy: 0.9960 - val_loss: 0.1586 - val_accuracy: 0.9552\n",
            "Epoch 75/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0195 - accuracy: 0.9937 - val_loss: 0.3650 - val_accuracy: 0.9324\n",
            "Epoch 76/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.1348 - val_accuracy: 0.9654\n",
            "Epoch 77/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.1727 - val_accuracy: 0.9611\n",
            "Epoch 78/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0154 - accuracy: 0.9941 - val_loss: 0.2452 - val_accuracy: 0.9189\n",
            "Epoch 79/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0134 - accuracy: 0.9949 - val_loss: 0.4158 - val_accuracy: 0.8868\n",
            "Epoch 80/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0180 - accuracy: 0.9947 - val_loss: 0.8778 - val_accuracy: 0.7956\n",
            "Epoch 81/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 0.3205 - val_accuracy: 0.9274\n",
            "Epoch 82/300\n",
            "149/149 [==============================] - 16s 100ms/step - loss: 0.0117 - accuracy: 0.9956 - val_loss: 0.1896 - val_accuracy: 0.9527\n",
            "Epoch 83/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.1422 - val_accuracy: 0.9721\n",
            "Epoch 84/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1404 - val_accuracy: 0.9671\n",
            "Epoch 85/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.1513 - val_accuracy: 0.9586\n",
            "Epoch 86/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0341 - accuracy: 0.9886 - val_loss: 0.2574 - val_accuracy: 0.9544\n",
            "Epoch 87/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0098 - accuracy: 0.9973 - val_loss: 0.1921 - val_accuracy: 0.9535\n",
            "Epoch 88/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 0.1363 - val_accuracy: 0.9654\n",
            "Epoch 89/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0078 - accuracy: 0.9970 - val_loss: 0.1311 - val_accuracy: 0.9688\n",
            "Epoch 90/300\n",
            "149/149 [==============================] - 15s 100ms/step - loss: 0.0109 - accuracy: 0.9962 - val_loss: 0.1773 - val_accuracy: 0.9595\n",
            "Epoch 91/300\n",
            "149/149 [==============================] - 16s 100ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.1441 - val_accuracy: 0.9620\n",
            "Epoch 92/300\n",
            "149/149 [==============================] - 16s 101ms/step - loss: 0.0187 - accuracy: 0.9949 - val_loss: 0.2358 - val_accuracy: 0.9502\n",
            "Epoch 93/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0028 - accuracy: 0.9998 - val_loss: 0.2092 - val_accuracy: 0.9535\n",
            "Epoch 94/300\n",
            "149/149 [==============================] - 16s 100ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.1736 - val_accuracy: 0.9578\n",
            "Epoch 95/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0157 - accuracy: 0.9949 - val_loss: 1.2550 - val_accuracy: 0.8184\n",
            "Epoch 96/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 0.1789 - val_accuracy: 0.9578\n",
            "Epoch 97/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.2282 - val_accuracy: 0.9307\n",
            "Epoch 98/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0083 - accuracy: 0.9981 - val_loss: 0.5759 - val_accuracy: 0.8758\n",
            "Epoch 99/300\n",
            "149/149 [==============================] - 16s 100ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.1301 - val_accuracy: 0.9662\n",
            "Epoch 100/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.3414 - val_accuracy: 0.9307\n",
            "Epoch 101/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0106 - accuracy: 0.9962 - val_loss: 0.4441 - val_accuracy: 0.9130\n",
            "Epoch 102/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0212 - accuracy: 0.9907 - val_loss: 0.4470 - val_accuracy: 0.9147\n",
            "Epoch 103/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0122 - accuracy: 0.9952 - val_loss: 0.1617 - val_accuracy: 0.9611\n",
            "Epoch 104/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.1577 - val_accuracy: 0.9578\n",
            "Epoch 105/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 6.0515e-04 - accuracy: 1.0000 - val_loss: 0.1537 - val_accuracy: 0.9637\n",
            "Epoch 106/300\n",
            "149/149 [==============================] - 15s 97ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.1795 - val_accuracy: 0.9586\n",
            "Epoch 107/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.1628 - val_accuracy: 0.9561\n",
            "Epoch 108/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0050 - accuracy: 0.9979 - val_loss: 0.1901 - val_accuracy: 0.9603\n",
            "Epoch 109/300\n",
            "149/149 [==============================] - 15s 97ms/step - loss: 0.0038 - accuracy: 0.9983 - val_loss: 0.1708 - val_accuracy: 0.9654\n",
            "Epoch 110/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.1576 - val_accuracy: 0.9688\n",
            "Epoch 111/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0140 - accuracy: 0.9947 - val_loss: 0.1935 - val_accuracy: 0.9502\n",
            "Epoch 112/300\n",
            "149/149 [==============================] - 15s 100ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.2022 - val_accuracy: 0.9392\n",
            "Epoch 113/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0097 - accuracy: 0.9964 - val_loss: 0.3090 - val_accuracy: 0.9130\n",
            "Epoch 114/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0072 - accuracy: 0.9970 - val_loss: 0.1524 - val_accuracy: 0.9637\n",
            "Epoch 115/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0023 - accuracy: 0.9998 - val_loss: 0.1414 - val_accuracy: 0.9586\n",
            "Epoch 116/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 6.1618e-04 - accuracy: 1.0000 - val_loss: 0.1346 - val_accuracy: 0.9696\n",
            "Epoch 117/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 6.5341e-04 - accuracy: 0.9998 - val_loss: 0.1354 - val_accuracy: 0.9704\n",
            "Epoch 118/300\n",
            "149/149 [==============================] - 16s 100ms/step - loss: 2.5943e-04 - accuracy: 1.0000 - val_loss: 0.1483 - val_accuracy: 0.9721\n",
            "Epoch 119/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 2.2956e-04 - accuracy: 1.0000 - val_loss: 0.1405 - val_accuracy: 0.9738\n",
            "Epoch 120/300\n",
            "149/149 [==============================] - 15s 100ms/step - loss: 1.1284e-04 - accuracy: 1.0000 - val_loss: 0.1419 - val_accuracy: 0.9738\n",
            "Epoch 121/300\n",
            "149/149 [==============================] - 16s 100ms/step - loss: 1.4259e-04 - accuracy: 1.0000 - val_loss: 0.1478 - val_accuracy: 0.9747\n",
            "Epoch 122/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 7.4256e-05 - accuracy: 1.0000 - val_loss: 0.1429 - val_accuracy: 0.9747\n",
            "Epoch 123/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 4.6045e-05 - accuracy: 1.0000 - val_loss: 0.1444 - val_accuracy: 0.9738\n",
            "Epoch 124/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 2.4053e-04 - accuracy: 1.0000 - val_loss: 0.1368 - val_accuracy: 0.9721\n",
            "Epoch 125/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.5795 - val_accuracy: 0.9316\n",
            "Epoch 126/300\n",
            "149/149 [==============================] - 16s 100ms/step - loss: 0.0505 - accuracy: 0.9810 - val_loss: 0.3479 - val_accuracy: 0.9274\n",
            "Epoch 127/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0198 - accuracy: 0.9933 - val_loss: 0.2427 - val_accuracy: 0.9434\n",
            "Epoch 128/300\n",
            "149/149 [==============================] - 16s 100ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.1554 - val_accuracy: 0.9637\n",
            "Epoch 129/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.1504 - val_accuracy: 0.9620\n",
            "Epoch 130/300\n",
            "149/149 [==============================] - 15s 100ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1762 - val_accuracy: 0.9561\n",
            "Epoch 131/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.1866 - val_accuracy: 0.9603\n",
            "Epoch 132/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.1845 - val_accuracy: 0.9586\n",
            "Epoch 133/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.2390 - val_accuracy: 0.9519\n",
            "Epoch 134/300\n",
            "149/149 [==============================] - 16s 100ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.1643 - val_accuracy: 0.9586\n",
            "Epoch 135/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 8.8879e-04 - accuracy: 0.9998 - val_loss: 0.1637 - val_accuracy: 0.9595\n",
            "Epoch 136/300\n",
            "149/149 [==============================] - 16s 100ms/step - loss: 5.8442e-04 - accuracy: 1.0000 - val_loss: 0.1916 - val_accuracy: 0.9611\n",
            "Epoch 137/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 8.5331e-04 - accuracy: 0.9996 - val_loss: 0.1771 - val_accuracy: 0.9603\n",
            "Epoch 138/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0662 - accuracy: 0.9798 - val_loss: 0.2197 - val_accuracy: 0.9417\n",
            "Epoch 139/300\n",
            "149/149 [==============================] - 15s 97ms/step - loss: 0.0137 - accuracy: 0.9956 - val_loss: 0.1806 - val_accuracy: 0.9603\n",
            "Epoch 140/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.1363 - val_accuracy: 0.9688\n",
            "Epoch 141/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.1298 - val_accuracy: 0.9637\n",
            "Epoch 142/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 6.6000e-04 - accuracy: 1.0000 - val_loss: 0.1333 - val_accuracy: 0.9662\n",
            "Epoch 143/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.1397 - val_accuracy: 0.9654\n",
            "Epoch 144/300\n",
            "149/149 [==============================] - 17s 108ms/step - loss: 0.0101 - accuracy: 0.9962 - val_loss: 0.1803 - val_accuracy: 0.9628\n",
            "Epoch 145/300\n",
            "149/149 [==============================] - 17s 106ms/step - loss: 9.3003e-04 - accuracy: 1.0000 - val_loss: 0.1368 - val_accuracy: 0.9688\n",
            "Epoch 146/300\n",
            "149/149 [==============================] - 16s 103ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.2060 - val_accuracy: 0.9434\n",
            "Epoch 147/300\n",
            "149/149 [==============================] - 16s 100ms/step - loss: 0.0142 - accuracy: 0.9941 - val_loss: 0.2996 - val_accuracy: 0.9383\n",
            "Epoch 148/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.1756 - val_accuracy: 0.9544\n",
            "Epoch 149/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 0.4009 - val_accuracy: 0.9122\n",
            "Epoch 150/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 9.2258e-04 - accuracy: 1.0000 - val_loss: 0.1586 - val_accuracy: 0.9620\n",
            "Epoch 151/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.1734 - val_accuracy: 0.9628\n",
            "Epoch 152/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.1936 - val_accuracy: 0.9645\n",
            "Epoch 153/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.2358 - val_accuracy: 0.9552\n",
            "Epoch 154/300\n",
            "149/149 [==============================] - 16s 100ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.1811 - val_accuracy: 0.9603\n",
            "Epoch 155/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.1498 - val_accuracy: 0.9535\n",
            "Epoch 156/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0043 - accuracy: 0.9979 - val_loss: 0.2186 - val_accuracy: 0.9485\n",
            "Epoch 157/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 0.2028 - val_accuracy: 0.9544\n",
            "Epoch 158/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.2123 - val_accuracy: 0.9569\n",
            "Epoch 159/300\n",
            "149/149 [==============================] - 16s 100ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.1939 - val_accuracy: 0.9586\n",
            "Epoch 160/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 7.6587e-04 - accuracy: 1.0000 - val_loss: 0.1900 - val_accuracy: 0.9645\n",
            "Epoch 161/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 3.6949e-04 - accuracy: 1.0000 - val_loss: 0.1805 - val_accuracy: 0.9654\n",
            "Epoch 162/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 2.2384e-04 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 0.9645\n",
            "Epoch 163/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 1.1357e-04 - accuracy: 1.0000 - val_loss: 0.1775 - val_accuracy: 0.9679\n",
            "Epoch 164/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 8.9028e-05 - accuracy: 1.0000 - val_loss: 0.1765 - val_accuracy: 0.9679\n",
            "Epoch 165/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 1.5513e-04 - accuracy: 1.0000 - val_loss: 0.1986 - val_accuracy: 0.9645\n",
            "Epoch 166/300\n",
            "149/149 [==============================] - 15s 97ms/step - loss: 1.6932e-04 - accuracy: 1.0000 - val_loss: 0.1819 - val_accuracy: 0.9645\n",
            "Epoch 167/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 1.0074e-04 - accuracy: 1.0000 - val_loss: 0.1837 - val_accuracy: 0.9679\n",
            "Epoch 168/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 1.2026e-04 - accuracy: 1.0000 - val_loss: 0.1822 - val_accuracy: 0.9662\n",
            "Epoch 169/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 9.0526e-05 - accuracy: 1.0000 - val_loss: 0.1888 - val_accuracy: 0.9688\n",
            "Epoch 170/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 5.0414e-05 - accuracy: 1.0000 - val_loss: 0.1867 - val_accuracy: 0.9696\n",
            "Epoch 171/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 6.0772e-05 - accuracy: 1.0000 - val_loss: 0.1775 - val_accuracy: 0.9671\n",
            "Epoch 172/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 8.6982e-05 - accuracy: 1.0000 - val_loss: 0.1806 - val_accuracy: 0.9696\n",
            "Epoch 173/300\n",
            "149/149 [==============================] - 15s 97ms/step - loss: 1.0492e-04 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9569\n",
            "Epoch 174/300\n",
            "149/149 [==============================] - 16s 101ms/step - loss: 0.0540 - accuracy: 0.9848 - val_loss: 0.3956 - val_accuracy: 0.9367\n",
            "Epoch 175/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0109 - accuracy: 0.9960 - val_loss: 0.1487 - val_accuracy: 0.9603\n",
            "Epoch 176/300\n",
            "149/149 [==============================] - 15s 97ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.1545 - val_accuracy: 0.9628\n",
            "Epoch 177/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0306 - accuracy: 0.9916 - val_loss: 0.2027 - val_accuracy: 0.9552\n",
            "Epoch 178/300\n",
            "149/149 [==============================] - 16s 100ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.1488 - val_accuracy: 0.9637\n",
            "Epoch 179/300\n",
            "149/149 [==============================] - 15s 100ms/step - loss: 6.3626e-04 - accuracy: 1.0000 - val_loss: 0.1592 - val_accuracy: 0.9645\n",
            "Epoch 180/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0086 - accuracy: 0.9975 - val_loss: 0.2467 - val_accuracy: 0.9434\n",
            "Epoch 181/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0473 - accuracy: 0.9848 - val_loss: 0.1564 - val_accuracy: 0.9603\n",
            "Epoch 182/300\n",
            "149/149 [==============================] - 16s 100ms/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.1122 - val_accuracy: 0.9645\n",
            "Epoch 183/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.1633 - val_accuracy: 0.9552\n",
            "Epoch 184/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0117 - accuracy: 0.9968 - val_loss: 0.1365 - val_accuracy: 0.9671\n",
            "Epoch 185/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.1632 - val_accuracy: 0.9569\n",
            "Epoch 186/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.1891 - val_accuracy: 0.9535\n",
            "Epoch 187/300\n",
            "149/149 [==============================] - 16s 101ms/step - loss: 0.0156 - accuracy: 0.9941 - val_loss: 0.1543 - val_accuracy: 0.9595\n",
            "Epoch 188/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0040 - accuracy: 0.9981 - val_loss: 0.1645 - val_accuracy: 0.9611\n",
            "Epoch 189/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.1799 - val_accuracy: 0.9595\n",
            "Epoch 190/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.1945 - val_accuracy: 0.9561\n",
            "Epoch 191/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.1865 - val_accuracy: 0.9645\n",
            "Epoch 192/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 7.0906e-04 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 0.9645\n",
            "Epoch 193/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 3.1371e-04 - accuracy: 1.0000 - val_loss: 0.1759 - val_accuracy: 0.9628\n",
            "Epoch 194/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 3.5834e-04 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 0.9611\n",
            "Epoch 195/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 2.4530e-04 - accuracy: 1.0000 - val_loss: 0.1777 - val_accuracy: 0.9595\n",
            "Epoch 196/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 4.4348e-04 - accuracy: 1.0000 - val_loss: 0.1598 - val_accuracy: 0.9620\n",
            "Epoch 197/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 1.5255e-04 - accuracy: 1.0000 - val_loss: 0.1590 - val_accuracy: 0.9645\n",
            "Epoch 198/300\n",
            "149/149 [==============================] - 16s 101ms/step - loss: 4.6700e-04 - accuracy: 0.9998 - val_loss: 0.1826 - val_accuracy: 0.9569\n",
            "Epoch 199/300\n",
            "149/149 [==============================] - 15s 100ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.3412 - val_accuracy: 0.9375\n",
            "Epoch 200/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 5.1830e-04 - accuracy: 0.9998 - val_loss: 0.2132 - val_accuracy: 0.9569\n",
            "Epoch 201/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.2370 - val_accuracy: 0.9544\n",
            "Epoch 202/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 4.0552e-04 - accuracy: 1.0000 - val_loss: 0.2177 - val_accuracy: 0.9595\n",
            "Epoch 203/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.1930 - val_accuracy: 0.9603\n",
            "Epoch 204/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0283 - accuracy: 0.9933 - val_loss: 0.3304 - val_accuracy: 0.9350\n",
            "Epoch 205/300\n",
            "149/149 [==============================] - 15s 97ms/step - loss: 0.0299 - accuracy: 0.9890 - val_loss: 0.1445 - val_accuracy: 0.9527\n",
            "Epoch 206/300\n",
            "149/149 [==============================] - 15s 100ms/step - loss: 0.0031 - accuracy: 0.9998 - val_loss: 0.1351 - val_accuracy: 0.9645\n",
            "Epoch 207/300\n",
            "149/149 [==============================] - 16s 100ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.1376 - val_accuracy: 0.9628\n",
            "Epoch 208/300\n",
            "149/149 [==============================] - 16s 100ms/step - loss: 8.3647e-04 - accuracy: 1.0000 - val_loss: 0.1343 - val_accuracy: 0.9671\n",
            "Epoch 209/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 6.9222e-04 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.9654\n",
            "Epoch 210/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 4.9398e-04 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.9637\n",
            "Epoch 211/300\n",
            "149/149 [==============================] - 16s 100ms/step - loss: 3.6509e-04 - accuracy: 1.0000 - val_loss: 0.1457 - val_accuracy: 0.9611\n",
            "Epoch 212/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 3.0009e-04 - accuracy: 1.0000 - val_loss: 0.1454 - val_accuracy: 0.9628\n",
            "Epoch 213/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 1.3897e-04 - accuracy: 1.0000 - val_loss: 0.1489 - val_accuracy: 0.9637\n",
            "Epoch 214/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 3.1648e-04 - accuracy: 1.0000 - val_loss: 0.1494 - val_accuracy: 0.9620\n",
            "Epoch 215/300\n",
            "149/149 [==============================] - 15s 100ms/step - loss: 4.8768e-04 - accuracy: 1.0000 - val_loss: 0.1472 - val_accuracy: 0.9645\n",
            "Epoch 216/300\n",
            "149/149 [==============================] - 15s 97ms/step - loss: 4.4373e-04 - accuracy: 1.0000 - val_loss: 0.1507 - val_accuracy: 0.9671\n",
            "Epoch 217/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 2.1326e-04 - accuracy: 1.0000 - val_loss: 0.1558 - val_accuracy: 0.9671\n",
            "Epoch 218/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 1.5023e-04 - accuracy: 1.0000 - val_loss: 0.1562 - val_accuracy: 0.9637\n",
            "Epoch 219/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 1.1301e-04 - accuracy: 1.0000 - val_loss: 0.1574 - val_accuracy: 0.9645\n",
            "Epoch 220/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 6.9080e-05 - accuracy: 1.0000 - val_loss: 0.1606 - val_accuracy: 0.9654\n",
            "Epoch 221/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 1.7801e-04 - accuracy: 1.0000 - val_loss: 0.1623 - val_accuracy: 0.9662\n",
            "Epoch 222/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 1.8059e-04 - accuracy: 1.0000 - val_loss: 0.1573 - val_accuracy: 0.9679\n",
            "Epoch 223/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 6.2022e-05 - accuracy: 1.0000 - val_loss: 0.1663 - val_accuracy: 0.9637\n",
            "Epoch 224/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 1.1088e-04 - accuracy: 1.0000 - val_loss: 0.1568 - val_accuracy: 0.9654\n",
            "Epoch 225/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 1.7391e-04 - accuracy: 1.0000 - val_loss: 0.1803 - val_accuracy: 0.9637\n",
            "Epoch 226/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 5.0003e-04 - accuracy: 1.0000 - val_loss: 0.2214 - val_accuracy: 0.9586\n",
            "Epoch 227/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0349 - accuracy: 0.9880 - val_loss: 1.4696 - val_accuracy: 0.8277\n",
            "Epoch 228/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0204 - accuracy: 0.9920 - val_loss: 0.2474 - val_accuracy: 0.9485\n",
            "Epoch 229/300\n",
            "149/149 [==============================] - 16s 100ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.1499 - val_accuracy: 0.9603\n",
            "Epoch 230/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 9.2852e-04 - accuracy: 1.0000 - val_loss: 0.1408 - val_accuracy: 0.9595\n",
            "Epoch 231/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 4.1608e-04 - accuracy: 1.0000 - val_loss: 0.1516 - val_accuracy: 0.9637\n",
            "Epoch 232/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.1609 - val_accuracy: 0.9637\n",
            "Epoch 233/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0185 - accuracy: 0.9941 - val_loss: 0.1403 - val_accuracy: 0.9578\n",
            "Epoch 234/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.1405 - val_accuracy: 0.9620\n",
            "Epoch 235/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 7.9695e-04 - accuracy: 1.0000 - val_loss: 0.1686 - val_accuracy: 0.9552\n",
            "Epoch 236/300\n",
            "149/149 [==============================] - 15s 97ms/step - loss: 7.7197e-04 - accuracy: 1.0000 - val_loss: 0.1330 - val_accuracy: 0.9645\n",
            "Epoch 237/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 4.6008e-04 - accuracy: 1.0000 - val_loss: 0.1430 - val_accuracy: 0.9637\n",
            "Epoch 238/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 3.9343e-04 - accuracy: 1.0000 - val_loss: 0.1241 - val_accuracy: 0.9620\n",
            "Epoch 239/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 1.9938e-04 - accuracy: 1.0000 - val_loss: 0.1361 - val_accuracy: 0.9611\n",
            "Epoch 240/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.1493 - val_accuracy: 0.9637\n",
            "Epoch 241/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0134 - accuracy: 0.9954 - val_loss: 0.2496 - val_accuracy: 0.9527\n",
            "Epoch 242/300\n",
            "149/149 [==============================] - 15s 97ms/step - loss: 0.0114 - accuracy: 0.9956 - val_loss: 0.1748 - val_accuracy: 0.9586\n",
            "Epoch 243/300\n",
            "149/149 [==============================] - 15s 97ms/step - loss: 0.0097 - accuracy: 0.9975 - val_loss: 0.1997 - val_accuracy: 0.9510\n",
            "Epoch 244/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.1737 - val_accuracy: 0.9611\n",
            "Epoch 245/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 5.6022e-04 - accuracy: 0.9998 - val_loss: 0.1788 - val_accuracy: 0.9595\n",
            "Epoch 246/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 2.7391e-04 - accuracy: 1.0000 - val_loss: 0.1820 - val_accuracy: 0.9578\n",
            "Epoch 247/300\n",
            "149/149 [==============================] - 15s 97ms/step - loss: 3.1057e-04 - accuracy: 1.0000 - val_loss: 0.1817 - val_accuracy: 0.9620\n",
            "Epoch 248/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 4.6472e-04 - accuracy: 0.9998 - val_loss: 0.2735 - val_accuracy: 0.9544\n",
            "Epoch 249/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 5.4766e-04 - accuracy: 1.0000 - val_loss: 0.1720 - val_accuracy: 0.9628\n",
            "Epoch 250/300\n",
            "149/149 [==============================] - 15s 100ms/step - loss: 2.6298e-04 - accuracy: 1.0000 - val_loss: 0.1728 - val_accuracy: 0.9637\n",
            "Epoch 251/300\n",
            "149/149 [==============================] - 16s 100ms/step - loss: 3.2230e-04 - accuracy: 1.0000 - val_loss: 0.1852 - val_accuracy: 0.9620\n",
            "Epoch 252/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 1.4502e-04 - accuracy: 1.0000 - val_loss: 0.1859 - val_accuracy: 0.9595\n",
            "Epoch 253/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 1.8057e-04 - accuracy: 1.0000 - val_loss: 0.1867 - val_accuracy: 0.9611\n",
            "Epoch 254/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 1.2279e-04 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.9645\n",
            "Epoch 255/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 1.5212e-04 - accuracy: 1.0000 - val_loss: 0.1802 - val_accuracy: 0.9620\n",
            "Epoch 256/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.2946 - val_accuracy: 0.9502\n",
            "Epoch 257/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0393 - accuracy: 0.9882 - val_loss: 0.1826 - val_accuracy: 0.9561\n",
            "Epoch 258/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.1476 - val_accuracy: 0.9671\n",
            "Epoch 259/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 9.8947e-04 - accuracy: 1.0000 - val_loss: 0.1422 - val_accuracy: 0.9679\n",
            "Epoch 260/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 4.4681e-04 - accuracy: 1.0000 - val_loss: 0.1372 - val_accuracy: 0.9671\n",
            "Epoch 261/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 3.3342e-04 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.9679\n",
            "Epoch 262/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 4.2622e-04 - accuracy: 0.9998 - val_loss: 0.1338 - val_accuracy: 0.9704\n",
            "Epoch 263/300\n",
            "149/149 [==============================] - 15s 97ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.1914 - val_accuracy: 0.9519\n",
            "Epoch 264/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.2077 - val_accuracy: 0.9637\n",
            "Epoch 265/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 0.0059 - accuracy: 0.9994 - val_loss: 0.1763 - val_accuracy: 0.9620\n",
            "Epoch 266/300\n",
            "149/149 [==============================] - 15s 97ms/step - loss: 0.0288 - accuracy: 0.9909 - val_loss: 0.2409 - val_accuracy: 0.9502\n",
            "Epoch 267/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 0.0046 - accuracy: 0.9983 - val_loss: 0.1300 - val_accuracy: 0.9688\n",
            "Epoch 268/300\n",
            "149/149 [==============================] - 15s 97ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.1436 - val_accuracy: 0.9654\n",
            "Epoch 269/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 6.0382e-04 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.9662\n",
            "Epoch 270/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 9.0703e-04 - accuracy: 0.9998 - val_loss: 0.1401 - val_accuracy: 0.9662\n",
            "Epoch 271/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 2.8173e-04 - accuracy: 1.0000 - val_loss: 0.1385 - val_accuracy: 0.9704\n",
            "Epoch 272/300\n",
            "149/149 [==============================] - 15s 100ms/step - loss: 3.1644e-04 - accuracy: 1.0000 - val_loss: 0.1371 - val_accuracy: 0.9671\n",
            "Epoch 273/300\n",
            "149/149 [==============================] - 16s 100ms/step - loss: 2.4251e-04 - accuracy: 1.0000 - val_loss: 0.1343 - val_accuracy: 0.9671\n",
            "Epoch 274/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 2.5610e-04 - accuracy: 1.0000 - val_loss: 0.1309 - val_accuracy: 0.9696\n",
            "Epoch 275/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 1.7950e-04 - accuracy: 1.0000 - val_loss: 0.1339 - val_accuracy: 0.9662\n",
            "Epoch 276/300\n",
            "149/149 [==============================] - 15s 100ms/step - loss: 1.3549e-04 - accuracy: 1.0000 - val_loss: 0.1375 - val_accuracy: 0.9679\n",
            "Epoch 277/300\n",
            "149/149 [==============================] - 15s 100ms/step - loss: 9.8865e-05 - accuracy: 1.0000 - val_loss: 0.1378 - val_accuracy: 0.9671\n",
            "Epoch 278/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 1.5185e-04 - accuracy: 1.0000 - val_loss: 0.1373 - val_accuracy: 0.9679\n",
            "Epoch 279/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 1.0906e-04 - accuracy: 1.0000 - val_loss: 0.1360 - val_accuracy: 0.9671\n",
            "Epoch 280/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 5.7641e-05 - accuracy: 1.0000 - val_loss: 0.1376 - val_accuracy: 0.9679\n",
            "Epoch 281/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 1.1873e-04 - accuracy: 1.0000 - val_loss: 0.1398 - val_accuracy: 0.9671\n",
            "Epoch 282/300\n",
            "149/149 [==============================] - 15s 97ms/step - loss: 6.5280e-05 - accuracy: 1.0000 - val_loss: 0.1416 - val_accuracy: 0.9696\n",
            "Epoch 283/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 1.0823e-04 - accuracy: 1.0000 - val_loss: 0.1412 - val_accuracy: 0.9671\n",
            "Epoch 284/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 5.8110e-05 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9696\n",
            "Epoch 285/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 5.4112e-05 - accuracy: 1.0000 - val_loss: 0.1406 - val_accuracy: 0.9662\n",
            "Epoch 286/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 3.4866e-05 - accuracy: 1.0000 - val_loss: 0.1429 - val_accuracy: 0.9679\n",
            "Epoch 287/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 4.3802e-05 - accuracy: 1.0000 - val_loss: 0.1426 - val_accuracy: 0.9662\n",
            "Epoch 288/300\n",
            "149/149 [==============================] - 16s 100ms/step - loss: 3.9818e-05 - accuracy: 1.0000 - val_loss: 0.1511 - val_accuracy: 0.9688\n",
            "Epoch 289/300\n",
            "149/149 [==============================] - 15s 97ms/step - loss: 7.0423e-05 - accuracy: 1.0000 - val_loss: 0.1512 - val_accuracy: 0.9679\n",
            "Epoch 290/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 7.2279e-05 - accuracy: 1.0000 - val_loss: 0.1560 - val_accuracy: 0.9671\n",
            "Epoch 291/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 3.9640e-05 - accuracy: 1.0000 - val_loss: 0.1541 - val_accuracy: 0.9688\n",
            "Epoch 292/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 1.9881e-05 - accuracy: 1.0000 - val_loss: 0.1519 - val_accuracy: 0.9679\n",
            "Epoch 293/300\n",
            "149/149 [==============================] - 16s 101ms/step - loss: 7.3407e-05 - accuracy: 1.0000 - val_loss: 0.1551 - val_accuracy: 0.9704\n",
            "Epoch 294/300\n",
            "149/149 [==============================] - 15s 98ms/step - loss: 3.7088e-05 - accuracy: 1.0000 - val_loss: 0.1598 - val_accuracy: 0.9688\n",
            "Epoch 295/300\n",
            "149/149 [==============================] - 16s 101ms/step - loss: 2.6585e-05 - accuracy: 1.0000 - val_loss: 0.1555 - val_accuracy: 0.9704\n",
            "Epoch 296/300\n",
            "149/149 [==============================] - 16s 100ms/step - loss: 3.1305e-05 - accuracy: 1.0000 - val_loss: 0.1537 - val_accuracy: 0.9696\n",
            "Epoch 297/300\n",
            "149/149 [==============================] - 16s 101ms/step - loss: 2.0982e-05 - accuracy: 1.0000 - val_loss: 0.1587 - val_accuracy: 0.9704\n",
            "Epoch 298/300\n",
            "149/149 [==============================] - 15s 100ms/step - loss: 3.5592e-05 - accuracy: 1.0000 - val_loss: 0.1621 - val_accuracy: 0.9662\n",
            "Epoch 299/300\n",
            "149/149 [==============================] - 15s 100ms/step - loss: 5.3258e-05 - accuracy: 1.0000 - val_loss: 0.1707 - val_accuracy: 0.9671\n",
            "Epoch 300/300\n",
            "149/149 [==============================] - 15s 99ms/step - loss: 9.4048e-05 - accuracy: 1.0000 - val_loss: 0.1755 - val_accuracy: 0.9645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet32"
      ],
      "metadata": {
        "id": "1fi7m2e1knMw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the model"
      ],
      "metadata": {
        "id": "5hgL62WekpCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res_32 = tf.keras.models.load_model(\n",
        "    \"/content/drive/MyDrive/MachineLearningProject/models/resnet/res_32.keras\",\n",
        "    safe_mode=False)\n",
        "\n",
        "res_32.summary()"
      ],
      "metadata": {
        "id": "ltdWYhAXkqcB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80647a30-8e1a-4d4a-87a1-19758fd89dbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"ResNet32\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " Input (InputLayer)          [(32, 224, 224, 3)]          0         []                            \n",
            "                                                                                                  \n",
            " Random_horizontal_flip (Ra  (32, 224, 224, 3)            0         ['Input[0][0]']               \n",
            " ndomFlip)                                                                                        \n",
            "                                                                                                  \n",
            " Random_contrast (RandomCon  (32, 224, 224, 3)            0         ['Random_horizontal_flip[0][0]\n",
            " trast)                                                             ']                            \n",
            "                                                                                                  \n",
            " Per_image_standardisation   (32, 224, 224, 3)            0         ['Random_contrast[0][0]']     \n",
            " (Lambda)                                                                                         \n",
            "                                                                                                  \n",
            " ZeroPadding (ZeroPadding2D  (32, 230, 230, 3)            0         ['Per_image_standardisation[0]\n",
            " )                                                                  [0]']                         \n",
            "                                                                                                  \n",
            " Conv1 (Conv2D)              (32, 112, 112, 64)           9472      ['ZeroPadding[0][0]']         \n",
            "                                                                                                  \n",
            " BatchNorm1 (BatchNormaliza  (32, 112, 112, 64)           256       ['Conv1[0][0]']               \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " ReLU1 (ReLU)                (32, 112, 112, 64)           0         ['BatchNorm1[0][0]']          \n",
            "                                                                                                  \n",
            " MaxPool (MaxPooling2D)      (32, 56, 56, 64)             0         ['ReLU1[0][0]']               \n",
            "                                                                                                  \n",
            " Conv1_1 (Conv2D)            (32, 56, 56, 64)             4160      ['MaxPool[0][0]']             \n",
            "                                                                                                  \n",
            " BatchNorm1_1 (BatchNormali  (32, 56, 56, 64)             256       ['Conv1_1[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " ReLU1_1 (ReLU)              (32, 56, 56, 64)             0         ['BatchNorm1_1[0][0]']        \n",
            "                                                                                                  \n",
            " Conv2_1 (Conv2D)            (32, 56, 56, 64)             36928     ['ReLU1_1[0][0]']             \n",
            "                                                                                                  \n",
            " BatchNorm2_1 (BatchNormali  (32, 56, 56, 64)             256       ['Conv2_1[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " ReLU2_1 (ReLU)              (32, 56, 56, 64)             0         ['BatchNorm2_1[0][0]']        \n",
            "                                                                                                  \n",
            " Conv3_1 (Conv2D)            (32, 56, 56, 256)            16640     ['ReLU2_1[0][0]']             \n",
            "                                                                                                  \n",
            " BatchNorm3_1 (BatchNormali  (32, 56, 56, 256)            1024      ['Conv3_1[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " Conv4_1 (Conv2D)            (32, 56, 56, 256)            16640     ['MaxPool[0][0]']             \n",
            "                                                                                                  \n",
            " ReLU3_1 (ReLU)              (32, 56, 56, 256)            0         ['BatchNorm3_1[0][0]']        \n",
            "                                                                                                  \n",
            " BatchNorm4_1 (BatchNormali  (32, 56, 56, 256)            1024      ['Conv4_1[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " SkipConnection_1 (Add)      (32, 56, 56, 256)            0         ['ReLU3_1[0][0]',             \n",
            "                                                                     'BatchNorm4_1[0][0]']        \n",
            "                                                                                                  \n",
            " ReLU4_1 (ReLU)              (32, 56, 56, 256)            0         ['SkipConnection_1[0][0]']    \n",
            "                                                                                                  \n",
            " Conv1_2 (Conv2D)            (32, 56, 56, 64)             16448     ['ReLU4_1[0][0]']             \n",
            "                                                                                                  \n",
            " BatchNorm1_2 (BatchNormali  (32, 56, 56, 64)             256       ['Conv1_2[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " ReLU1_2 (ReLU)              (32, 56, 56, 64)             0         ['BatchNorm1_2[0][0]']        \n",
            "                                                                                                  \n",
            " Conv2_2 (Conv2D)            (32, 56, 56, 64)             36928     ['ReLU1_2[0][0]']             \n",
            "                                                                                                  \n",
            " BatchNorm2_2 (BatchNormali  (32, 56, 56, 64)             256       ['Conv2_2[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " ReLU2_2 (ReLU)              (32, 56, 56, 64)             0         ['BatchNorm2_2[0][0]']        \n",
            "                                                                                                  \n",
            " Conv3_2 (Conv2D)            (32, 56, 56, 256)            16640     ['ReLU2_2[0][0]']             \n",
            "                                                                                                  \n",
            " BatchNorm3_2 (BatchNormali  (32, 56, 56, 256)            1024      ['Conv3_2[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " ReLU3_2 (ReLU)              (32, 56, 56, 256)            0         ['BatchNorm3_2[0][0]']        \n",
            "                                                                                                  \n",
            " SkipConnection_2 (Add)      (32, 56, 56, 256)            0         ['ReLU3_2[0][0]',             \n",
            "                                                                     'ReLU4_1[0][0]']             \n",
            "                                                                                                  \n",
            " ReLU4_2 (ReLU)              (32, 56, 56, 256)            0         ['SkipConnection_2[0][0]']    \n",
            "                                                                                                  \n",
            " Conv1_3 (Conv2D)            (32, 56, 56, 64)             16448     ['ReLU4_2[0][0]']             \n",
            "                                                                                                  \n",
            " BatchNorm1_3 (BatchNormali  (32, 56, 56, 64)             256       ['Conv1_3[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " ReLU1_3 (ReLU)              (32, 56, 56, 64)             0         ['BatchNorm1_3[0][0]']        \n",
            "                                                                                                  \n",
            " Conv2_3 (Conv2D)            (32, 56, 56, 64)             36928     ['ReLU1_3[0][0]']             \n",
            "                                                                                                  \n",
            " BatchNorm2_3 (BatchNormali  (32, 56, 56, 64)             256       ['Conv2_3[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " ReLU2_3 (ReLU)              (32, 56, 56, 64)             0         ['BatchNorm2_3[0][0]']        \n",
            "                                                                                                  \n",
            " Conv3_3 (Conv2D)            (32, 56, 56, 256)            16640     ['ReLU2_3[0][0]']             \n",
            "                                                                                                  \n",
            " BatchNorm3_3 (BatchNormali  (32, 56, 56, 256)            1024      ['Conv3_3[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " ReLU3_3 (ReLU)              (32, 56, 56, 256)            0         ['BatchNorm3_3[0][0]']        \n",
            "                                                                                                  \n",
            " SkipConnection_3 (Add)      (32, 56, 56, 256)            0         ['ReLU3_3[0][0]',             \n",
            "                                                                     'ReLU4_2[0][0]']             \n",
            "                                                                                                  \n",
            " ReLU4_3 (ReLU)              (32, 56, 56, 256)            0         ['SkipConnection_3[0][0]']    \n",
            "                                                                                                  \n",
            " Conv1_4 (Conv2D)            (32, 28, 28, 128)            32896     ['ReLU4_3[0][0]']             \n",
            "                                                                                                  \n",
            " BatchNorm1_4 (BatchNormali  (32, 28, 28, 128)            512       ['Conv1_4[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " ReLU1_4 (ReLU)              (32, 28, 28, 128)            0         ['BatchNorm1_4[0][0]']        \n",
            "                                                                                                  \n",
            " Conv2_4 (Conv2D)            (32, 28, 28, 128)            147584    ['ReLU1_4[0][0]']             \n",
            "                                                                                                  \n",
            " BatchNorm2_4 (BatchNormali  (32, 28, 28, 128)            512       ['Conv2_4[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " ReLU2_4 (ReLU)              (32, 28, 28, 128)            0         ['BatchNorm2_4[0][0]']        \n",
            "                                                                                                  \n",
            " Conv3_4 (Conv2D)            (32, 28, 28, 512)            66048     ['ReLU2_4[0][0]']             \n",
            "                                                                                                  \n",
            " BatchNorm3_4 (BatchNormali  (32, 28, 28, 512)            2048      ['Conv3_4[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " Conv4_4 (Conv2D)            (32, 28, 28, 512)            131584    ['ReLU4_3[0][0]']             \n",
            "                                                                                                  \n",
            " ReLU3_4 (ReLU)              (32, 28, 28, 512)            0         ['BatchNorm3_4[0][0]']        \n",
            "                                                                                                  \n",
            " BatchNorm4_4 (BatchNormali  (32, 28, 28, 512)            2048      ['Conv4_4[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " SkipConnection_4 (Add)      (32, 28, 28, 512)            0         ['ReLU3_4[0][0]',             \n",
            "                                                                     'BatchNorm4_4[0][0]']        \n",
            "                                                                                                  \n",
            " ReLU4_4 (ReLU)              (32, 28, 28, 512)            0         ['SkipConnection_4[0][0]']    \n",
            "                                                                                                  \n",
            " Conv1_5 (Conv2D)            (32, 28, 28, 128)            65664     ['ReLU4_4[0][0]']             \n",
            "                                                                                                  \n",
            " BatchNorm1_5 (BatchNormali  (32, 28, 28, 128)            512       ['Conv1_5[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " ReLU1_5 (ReLU)              (32, 28, 28, 128)            0         ['BatchNorm1_5[0][0]']        \n",
            "                                                                                                  \n",
            " Conv2_5 (Conv2D)            (32, 28, 28, 128)            147584    ['ReLU1_5[0][0]']             \n",
            "                                                                                                  \n",
            " BatchNorm2_5 (BatchNormali  (32, 28, 28, 128)            512       ['Conv2_5[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " ReLU2_5 (ReLU)              (32, 28, 28, 128)            0         ['BatchNorm2_5[0][0]']        \n",
            "                                                                                                  \n",
            " Conv3_5 (Conv2D)            (32, 28, 28, 512)            66048     ['ReLU2_5[0][0]']             \n",
            "                                                                                                  \n",
            " BatchNorm3_5 (BatchNormali  (32, 28, 28, 512)            2048      ['Conv3_5[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " ReLU3_5 (ReLU)              (32, 28, 28, 512)            0         ['BatchNorm3_5[0][0]']        \n",
            "                                                                                                  \n",
            " SkipConnection_5 (Add)      (32, 28, 28, 512)            0         ['ReLU3_5[0][0]',             \n",
            "                                                                     'ReLU4_4[0][0]']             \n",
            "                                                                                                  \n",
            " ReLU4_5 (ReLU)              (32, 28, 28, 512)            0         ['SkipConnection_5[0][0]']    \n",
            "                                                                                                  \n",
            " Conv1_6 (Conv2D)            (32, 28, 28, 128)            65664     ['ReLU4_5[0][0]']             \n",
            "                                                                                                  \n",
            " BatchNorm1_6 (BatchNormali  (32, 28, 28, 128)            512       ['Conv1_6[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " ReLU1_6 (ReLU)              (32, 28, 28, 128)            0         ['BatchNorm1_6[0][0]']        \n",
            "                                                                                                  \n",
            " Conv2_6 (Conv2D)            (32, 28, 28, 128)            147584    ['ReLU1_6[0][0]']             \n",
            "                                                                                                  \n",
            " BatchNorm2_6 (BatchNormali  (32, 28, 28, 128)            512       ['Conv2_6[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " ReLU2_6 (ReLU)              (32, 28, 28, 128)            0         ['BatchNorm2_6[0][0]']        \n",
            "                                                                                                  \n",
            " Conv3_6 (Conv2D)            (32, 28, 28, 512)            66048     ['ReLU2_6[0][0]']             \n",
            "                                                                                                  \n",
            " BatchNorm3_6 (BatchNormali  (32, 28, 28, 512)            2048      ['Conv3_6[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " ReLU3_6 (ReLU)              (32, 28, 28, 512)            0         ['BatchNorm3_6[0][0]']        \n",
            "                                                                                                  \n",
            " SkipConnection_6 (Add)      (32, 28, 28, 512)            0         ['ReLU3_6[0][0]',             \n",
            "                                                                     'ReLU4_5[0][0]']             \n",
            "                                                                                                  \n",
            " ReLU4_6 (ReLU)              (32, 28, 28, 512)            0         ['SkipConnection_6[0][0]']    \n",
            "                                                                                                  \n",
            " Conv1_7 (Conv2D)            (32, 28, 28, 128)            65664     ['ReLU4_6[0][0]']             \n",
            "                                                                                                  \n",
            " BatchNorm1_7 (BatchNormali  (32, 28, 28, 128)            512       ['Conv1_7[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " ReLU1_7 (ReLU)              (32, 28, 28, 128)            0         ['BatchNorm1_7[0][0]']        \n",
            "                                                                                                  \n",
            " Conv2_7 (Conv2D)            (32, 28, 28, 128)            147584    ['ReLU1_7[0][0]']             \n",
            "                                                                                                  \n",
            " BatchNorm2_7 (BatchNormali  (32, 28, 28, 128)            512       ['Conv2_7[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " ReLU2_7 (ReLU)              (32, 28, 28, 128)            0         ['BatchNorm2_7[0][0]']        \n",
            "                                                                                                  \n",
            " Conv3_7 (Conv2D)            (32, 28, 28, 512)            66048     ['ReLU2_7[0][0]']             \n",
            "                                                                                                  \n",
            " BatchNorm3_7 (BatchNormali  (32, 28, 28, 512)            2048      ['Conv3_7[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " ReLU3_7 (ReLU)              (32, 28, 28, 512)            0         ['BatchNorm3_7[0][0]']        \n",
            "                                                                                                  \n",
            " SkipConnection_7 (Add)      (32, 28, 28, 512)            0         ['ReLU3_7[0][0]',             \n",
            "                                                                     'ReLU4_6[0][0]']             \n",
            "                                                                                                  \n",
            " ReLU4_7 (ReLU)              (32, 28, 28, 512)            0         ['SkipConnection_7[0][0]']    \n",
            "                                                                                                  \n",
            " Conv1_8 (Conv2D)            (32, 14, 14, 256)            131328    ['ReLU4_7[0][0]']             \n",
            "                                                                                                  \n",
            " BatchNorm1_8 (BatchNormali  (32, 14, 14, 256)            1024      ['Conv1_8[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " ReLU1_8 (ReLU)              (32, 14, 14, 256)            0         ['BatchNorm1_8[0][0]']        \n",
            "                                                                                                  \n",
            " Conv2_8 (Conv2D)            (32, 14, 14, 256)            590080    ['ReLU1_8[0][0]']             \n",
            "                                                                                                  \n",
            " BatchNorm2_8 (BatchNormali  (32, 14, 14, 256)            1024      ['Conv2_8[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " ReLU2_8 (ReLU)              (32, 14, 14, 256)            0         ['BatchNorm2_8[0][0]']        \n",
            "                                                                                                  \n",
            " Conv3_8 (Conv2D)            (32, 14, 14, 1024)           263168    ['ReLU2_8[0][0]']             \n",
            "                                                                                                  \n",
            " BatchNorm3_8 (BatchNormali  (32, 14, 14, 1024)           4096      ['Conv3_8[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " Conv4_8 (Conv2D)            (32, 14, 14, 1024)           525312    ['ReLU4_7[0][0]']             \n",
            "                                                                                                  \n",
            " ReLU3_8 (ReLU)              (32, 14, 14, 1024)           0         ['BatchNorm3_8[0][0]']        \n",
            "                                                                                                  \n",
            " BatchNorm4_8 (BatchNormali  (32, 14, 14, 1024)           4096      ['Conv4_8[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " SkipConnection_8 (Add)      (32, 14, 14, 1024)           0         ['ReLU3_8[0][0]',             \n",
            "                                                                     'BatchNorm4_8[0][0]']        \n",
            "                                                                                                  \n",
            " ReLU4_8 (ReLU)              (32, 14, 14, 1024)           0         ['SkipConnection_8[0][0]']    \n",
            "                                                                                                  \n",
            " Conv1_9 (Conv2D)            (32, 14, 14, 256)            262400    ['ReLU4_8[0][0]']             \n",
            "                                                                                                  \n",
            " BatchNorm1_9 (BatchNormali  (32, 14, 14, 256)            1024      ['Conv1_9[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " ReLU1_9 (ReLU)              (32, 14, 14, 256)            0         ['BatchNorm1_9[0][0]']        \n",
            "                                                                                                  \n",
            " Conv2_9 (Conv2D)            (32, 14, 14, 256)            590080    ['ReLU1_9[0][0]']             \n",
            "                                                                                                  \n",
            " BatchNorm2_9 (BatchNormali  (32, 14, 14, 256)            1024      ['Conv2_9[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " ReLU2_9 (ReLU)              (32, 14, 14, 256)            0         ['BatchNorm2_9[0][0]']        \n",
            "                                                                                                  \n",
            " Conv3_9 (Conv2D)            (32, 14, 14, 1024)           263168    ['ReLU2_9[0][0]']             \n",
            "                                                                                                  \n",
            " BatchNorm3_9 (BatchNormali  (32, 14, 14, 1024)           4096      ['Conv3_9[0][0]']             \n",
            " zation)                                                                                          \n",
            "                                                                                                  \n",
            " ReLU3_9 (ReLU)              (32, 14, 14, 1024)           0         ['BatchNorm3_9[0][0]']        \n",
            "                                                                                                  \n",
            " SkipConnection_9 (Add)      (32, 14, 14, 1024)           0         ['ReLU3_9[0][0]',             \n",
            "                                                                     'ReLU4_8[0][0]']             \n",
            "                                                                                                  \n",
            " ReLU4_9 (ReLU)              (32, 14, 14, 1024)           0         ['SkipConnection_9[0][0]']    \n",
            "                                                                                                  \n",
            " Conv1_10 (Conv2D)           (32, 14, 14, 256)            262400    ['ReLU4_9[0][0]']             \n",
            "                                                                                                  \n",
            " BatchNorm1_10 (BatchNormal  (32, 14, 14, 256)            1024      ['Conv1_10[0][0]']            \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " ReLU1_10 (ReLU)             (32, 14, 14, 256)            0         ['BatchNorm1_10[0][0]']       \n",
            "                                                                                                  \n",
            " Conv2_10 (Conv2D)           (32, 14, 14, 256)            590080    ['ReLU1_10[0][0]']            \n",
            "                                                                                                  \n",
            " BatchNorm2_10 (BatchNormal  (32, 14, 14, 256)            1024      ['Conv2_10[0][0]']            \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " ReLU2_10 (ReLU)             (32, 14, 14, 256)            0         ['BatchNorm2_10[0][0]']       \n",
            "                                                                                                  \n",
            " Conv3_10 (Conv2D)           (32, 14, 14, 1024)           263168    ['ReLU2_10[0][0]']            \n",
            "                                                                                                  \n",
            " BatchNorm3_10 (BatchNormal  (32, 14, 14, 1024)           4096      ['Conv3_10[0][0]']            \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " ReLU3_10 (ReLU)             (32, 14, 14, 1024)           0         ['BatchNorm3_10[0][0]']       \n",
            "                                                                                                  \n",
            " SkipConnection_10 (Add)     (32, 14, 14, 1024)           0         ['ReLU3_10[0][0]',            \n",
            "                                                                     'ReLU4_9[0][0]']             \n",
            "                                                                                                  \n",
            " ReLU4_10 (ReLU)             (32, 14, 14, 1024)           0         ['SkipConnection_10[0][0]']   \n",
            "                                                                                                  \n",
            " GlobalAvgPooling (GlobalAv  (32, 1024)                   0         ['ReLU4_10[0][0]']            \n",
            " eragePooling2D)                                                                                  \n",
            "                                                                                                  \n",
            " Output (Dense)              (32, 1)                      1025      ['GlobalAvgPooling[0][0]']    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5224833 (19.93 MB)\n",
            "Trainable params: 5203457 (19.85 MB)\n",
            "Non-trainable params: 21376 (83.50 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compiling the model"
      ],
      "metadata": {
        "id": "CPOVoZytkuvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res_32.compile(loss=\"binary_crossentropy\",\n",
        "               optimizer=Adam(learning_rate=0.0005,\n",
        "                              beta_1=0.99),\n",
        "               metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "CjK_-U_bkyIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Checkpoint Callback"
      ],
      "metadata": {
        "id": "U6WoCE-nkzw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res_32_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=\"/content/drive/MyDrive/MachineLearningProject/model_weights/resnet/res_32.keras\",\n",
        "    save_weights_only=True,\n",
        "    save_best_only=False)\n",
        "\n",
        "res_32_csv_logger = CSVLogger('/content/drive/MyDrive/MachineLearningProject/histories/resnet/res_32.log')"
      ],
      "metadata": {
        "id": "6dtKcKw7k15D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Learning rate"
      ],
      "metadata": {
        "id": "q9_JkuH1k5rh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)"
      ],
      "metadata": {
        "id": "qHxPT7AnlUs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fitting the model"
      ],
      "metadata": {
        "id": "yXFqR2cVmmLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res_32_history = res_32.fit(train_ds,\n",
        "                            epochs=300,\n",
        "                            steps_per_epoch=len(train_ds),\n",
        "                            validation_data=val_ds,\n",
        "                            validation_steps=len(val_ds),\n",
        "                            callbacks=[res_32_checkpoint, lr_scheduler, res_32_csv_logger])"
      ],
      "metadata": {
        "id": "Dl2uprLfmtOG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ee1001f-aa84-421f-87c9-cb42b3fca55b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "149/149 [==============================] - 323s 2s/step - loss: 0.4662 - accuracy: 0.8081 - val_loss: 7.8135 - val_accuracy: 0.4840 - lr: 5.0000e-04\n",
            "Epoch 2/300\n",
            "149/149 [==============================] - 18s 114ms/step - loss: 0.3172 - accuracy: 0.8720 - val_loss: 2.7063 - val_accuracy: 0.5524 - lr: 5.0000e-04\n",
            "Epoch 3/300\n",
            "149/149 [==============================] - 18s 114ms/step - loss: 0.2449 - accuracy: 0.9072 - val_loss: 0.2427 - val_accuracy: 0.9105 - lr: 5.0000e-04\n",
            "Epoch 4/300\n",
            "149/149 [==============================] - 18s 115ms/step - loss: 0.2162 - accuracy: 0.9174 - val_loss: 0.4504 - val_accuracy: 0.8176 - lr: 5.0000e-04\n",
            "Epoch 5/300\n",
            "149/149 [==============================] - 18s 114ms/step - loss: 0.2090 - accuracy: 0.9148 - val_loss: 0.2083 - val_accuracy: 0.9198 - lr: 5.0000e-04\n",
            "Epoch 6/300\n",
            "149/149 [==============================] - 18s 113ms/step - loss: 0.1881 - accuracy: 0.9275 - val_loss: 0.2505 - val_accuracy: 0.9029 - lr: 5.0000e-04\n",
            "Epoch 7/300\n",
            "149/149 [==============================] - 18s 114ms/step - loss: 0.1669 - accuracy: 0.9372 - val_loss: 0.2463 - val_accuracy: 0.9105 - lr: 5.0000e-04\n",
            "Epoch 8/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 0.1599 - accuracy: 0.9410 - val_loss: 0.2011 - val_accuracy: 0.9257 - lr: 5.0000e-04\n",
            "Epoch 9/300\n",
            "149/149 [==============================] - 18s 114ms/step - loss: 0.1389 - accuracy: 0.9483 - val_loss: 0.2825 - val_accuracy: 0.8953 - lr: 5.0000e-04\n",
            "Epoch 10/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 0.1260 - accuracy: 0.9496 - val_loss: 0.8470 - val_accuracy: 0.7897 - lr: 5.0000e-04\n",
            "Epoch 11/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 0.1262 - accuracy: 0.9551 - val_loss: 0.2032 - val_accuracy: 0.9274 - lr: 5.0000e-04\n",
            "Epoch 12/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 0.1197 - accuracy: 0.9511 - val_loss: 0.2584 - val_accuracy: 0.9071 - lr: 5.0000e-04\n",
            "Epoch 13/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 0.0955 - accuracy: 0.9625 - val_loss: 0.1943 - val_accuracy: 0.9392 - lr: 5.0000e-04\n",
            "Epoch 14/300\n",
            "149/149 [==============================] - 18s 113ms/step - loss: 0.0945 - accuracy: 0.9627 - val_loss: 0.2394 - val_accuracy: 0.9223 - lr: 5.0000e-04\n",
            "Epoch 15/300\n",
            "149/149 [==============================] - 18s 114ms/step - loss: 0.0947 - accuracy: 0.9637 - val_loss: 1.0346 - val_accuracy: 0.7416 - lr: 5.0000e-04\n",
            "Epoch 16/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 0.0760 - accuracy: 0.9747 - val_loss: 0.2428 - val_accuracy: 0.9291 - lr: 4.7561e-04\n",
            "Epoch 17/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 0.0770 - accuracy: 0.9701 - val_loss: 0.3572 - val_accuracy: 0.9189 - lr: 4.5242e-04\n",
            "Epoch 18/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 0.0546 - accuracy: 0.9804 - val_loss: 0.1475 - val_accuracy: 0.9535 - lr: 4.3035e-04\n",
            "Epoch 19/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 0.0376 - accuracy: 0.9865 - val_loss: 0.2015 - val_accuracy: 0.9375 - lr: 4.0937e-04\n",
            "Epoch 20/300\n",
            "149/149 [==============================] - 18s 113ms/step - loss: 0.0519 - accuracy: 0.9808 - val_loss: 0.1646 - val_accuracy: 0.9468 - lr: 3.8940e-04\n",
            "Epoch 21/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 0.0563 - accuracy: 0.9793 - val_loss: 0.1599 - val_accuracy: 0.9434 - lr: 3.7041e-04\n",
            "Epoch 22/300\n",
            "149/149 [==============================] - 18s 114ms/step - loss: 0.0404 - accuracy: 0.9873 - val_loss: 0.2137 - val_accuracy: 0.9367 - lr: 3.5234e-04\n",
            "Epoch 23/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 0.0259 - accuracy: 0.9907 - val_loss: 0.1582 - val_accuracy: 0.9485 - lr: 3.3516e-04\n",
            "Epoch 24/300\n",
            "149/149 [==============================] - 18s 114ms/step - loss: 0.0391 - accuracy: 0.9857 - val_loss: 0.3351 - val_accuracy: 0.9155 - lr: 3.1881e-04\n",
            "Epoch 25/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 0.0295 - accuracy: 0.9909 - val_loss: 0.1936 - val_accuracy: 0.9459 - lr: 3.0327e-04\n",
            "Epoch 26/300\n",
            "149/149 [==============================] - 18s 114ms/step - loss: 0.0191 - accuracy: 0.9933 - val_loss: 0.1817 - val_accuracy: 0.9392 - lr: 2.8848e-04\n",
            "Epoch 27/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 0.0143 - accuracy: 0.9956 - val_loss: 0.1789 - val_accuracy: 0.9569 - lr: 2.7441e-04\n",
            "Epoch 28/300\n",
            "149/149 [==============================] - 18s 113ms/step - loss: 0.0086 - accuracy: 0.9964 - val_loss: 0.1470 - val_accuracy: 0.9552 - lr: 2.6102e-04\n",
            "Epoch 29/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 0.0152 - accuracy: 0.9960 - val_loss: 0.2128 - val_accuracy: 0.9519 - lr: 2.4829e-04\n",
            "Epoch 30/300\n",
            "149/149 [==============================] - 18s 113ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.1982 - val_accuracy: 0.9552 - lr: 2.3618e-04\n",
            "Epoch 31/300\n",
            "149/149 [==============================] - 18s 113ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.1675 - val_accuracy: 0.9527 - lr: 2.2466e-04\n",
            "Epoch 32/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 0.0108 - accuracy: 0.9973 - val_loss: 0.1398 - val_accuracy: 0.9595 - lr: 2.1371e-04\n",
            "Epoch 33/300\n",
            "149/149 [==============================] - 18s 114ms/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.1817 - val_accuracy: 0.9502 - lr: 2.0328e-04\n",
            "Epoch 34/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.1472 - val_accuracy: 0.9620 - lr: 1.9337e-04\n",
            "Epoch 35/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 0.0116 - accuracy: 0.9954 - val_loss: 0.1950 - val_accuracy: 0.9510 - lr: 1.8394e-04\n",
            "Epoch 36/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 0.0150 - accuracy: 0.9952 - val_loss: 0.1800 - val_accuracy: 0.9603 - lr: 1.7497e-04\n",
            "Epoch 37/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 0.0088 - accuracy: 0.9975 - val_loss: 0.1974 - val_accuracy: 0.9561 - lr: 1.6644e-04\n",
            "Epoch 38/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.2014 - val_accuracy: 0.9544 - lr: 1.5832e-04\n",
            "Epoch 39/300\n",
            "149/149 [==============================] - 18s 113ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 0.1279 - val_accuracy: 0.9713 - lr: 1.5060e-04\n",
            "Epoch 40/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 0.0041 - accuracy: 0.9985 - val_loss: 0.1294 - val_accuracy: 0.9662 - lr: 1.4325e-04\n",
            "Epoch 41/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 0.1482 - val_accuracy: 0.9620 - lr: 1.3627e-04\n",
            "Epoch 42/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.1649 - val_accuracy: 0.9637 - lr: 1.2962e-04\n",
            "Epoch 43/300\n",
            "149/149 [==============================] - 18s 113ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.1712 - val_accuracy: 0.9595 - lr: 1.2330e-04\n",
            "Epoch 44/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.1703 - val_accuracy: 0.9611 - lr: 1.1729e-04\n",
            "Epoch 45/300\n",
            "149/149 [==============================] - 18s 113ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1729 - val_accuracy: 0.9611 - lr: 1.1157e-04\n",
            "Epoch 46/300\n",
            "149/149 [==============================] - 18s 114ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.1568 - val_accuracy: 0.9645 - lr: 1.0612e-04\n",
            "Epoch 47/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 6.8849e-04 - accuracy: 1.0000 - val_loss: 0.1547 - val_accuracy: 0.9645 - lr: 1.0095e-04\n",
            "Epoch 48/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 6.0716e-04 - accuracy: 1.0000 - val_loss: 0.1523 - val_accuracy: 0.9645 - lr: 9.6025e-05\n",
            "Epoch 49/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 4.2822e-04 - accuracy: 1.0000 - val_loss: 0.1564 - val_accuracy: 0.9671 - lr: 9.1342e-05\n",
            "Epoch 50/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 2.6569e-04 - accuracy: 1.0000 - val_loss: 0.1568 - val_accuracy: 0.9662 - lr: 8.6887e-05\n",
            "Epoch 51/300\n",
            "149/149 [==============================] - 18s 113ms/step - loss: 4.6168e-04 - accuracy: 1.0000 - val_loss: 0.1488 - val_accuracy: 0.9637 - lr: 8.2650e-05\n",
            "Epoch 52/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 3.7192e-04 - accuracy: 1.0000 - val_loss: 0.1534 - val_accuracy: 0.9671 - lr: 7.8619e-05\n",
            "Epoch 53/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 4.5543e-04 - accuracy: 0.9998 - val_loss: 0.1559 - val_accuracy: 0.9662 - lr: 7.4784e-05\n",
            "Epoch 54/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 4.9883e-04 - accuracy: 1.0000 - val_loss: 0.1622 - val_accuracy: 0.9671 - lr: 7.1137e-05\n",
            "Epoch 55/300\n",
            "149/149 [==============================] - 18s 113ms/step - loss: 3.5475e-04 - accuracy: 1.0000 - val_loss: 0.1482 - val_accuracy: 0.9645 - lr: 6.7668e-05\n",
            "Epoch 56/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 4.1364e-04 - accuracy: 0.9998 - val_loss: 0.1525 - val_accuracy: 0.9620 - lr: 6.4368e-05\n",
            "Epoch 57/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 4.8514e-04 - accuracy: 1.0000 - val_loss: 0.1560 - val_accuracy: 0.9713 - lr: 6.1228e-05\n",
            "Epoch 58/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.1725 - val_accuracy: 0.9679 - lr: 5.8242e-05\n",
            "Epoch 59/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 7.7966e-04 - accuracy: 0.9998 - val_loss: 0.1572 - val_accuracy: 0.9688 - lr: 5.5402e-05\n",
            "Epoch 60/300\n",
            "149/149 [==============================] - 18s 113ms/step - loss: 5.5762e-04 - accuracy: 0.9998 - val_loss: 0.1570 - val_accuracy: 0.9679 - lr: 5.2700e-05\n",
            "Epoch 61/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 1.7724e-04 - accuracy: 1.0000 - val_loss: 0.1617 - val_accuracy: 0.9679 - lr: 5.0129e-05\n",
            "Epoch 62/300\n",
            "149/149 [==============================] - 18s 113ms/step - loss: 4.3342e-04 - accuracy: 1.0000 - val_loss: 0.1645 - val_accuracy: 0.9696 - lr: 4.7685e-05\n",
            "Epoch 63/300\n",
            "149/149 [==============================] - 18s 113ms/step - loss: 2.6542e-04 - accuracy: 1.0000 - val_loss: 0.1606 - val_accuracy: 0.9688 - lr: 4.5359e-05\n",
            "Epoch 64/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 3.8835e-04 - accuracy: 0.9998 - val_loss: 0.1550 - val_accuracy: 0.9679 - lr: 4.3147e-05\n",
            "Epoch 65/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.1811 - val_accuracy: 0.9578 - lr: 4.1043e-05\n",
            "Epoch 66/300\n",
            "149/149 [==============================] - 18s 114ms/step - loss: 9.8295e-04 - accuracy: 0.9998 - val_loss: 0.1976 - val_accuracy: 0.9527 - lr: 3.9041e-05\n",
            "Epoch 67/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 3.5373e-04 - accuracy: 1.0000 - val_loss: 0.1752 - val_accuracy: 0.9603 - lr: 3.7137e-05\n",
            "Epoch 68/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 7.9970e-04 - accuracy: 0.9996 - val_loss: 0.1843 - val_accuracy: 0.9620 - lr: 3.5326e-05\n",
            "Epoch 69/300\n",
            "149/149 [==============================] - 18s 113ms/step - loss: 3.6294e-04 - accuracy: 1.0000 - val_loss: 0.1855 - val_accuracy: 0.9645 - lr: 3.3603e-05\n",
            "Epoch 70/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 3.9210e-04 - accuracy: 1.0000 - val_loss: 0.1763 - val_accuracy: 0.9620 - lr: 3.1964e-05\n",
            "Epoch 71/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 2.6328e-04 - accuracy: 1.0000 - val_loss: 0.1923 - val_accuracy: 0.9628 - lr: 3.0405e-05\n",
            "Epoch 72/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 9.1293e-04 - accuracy: 0.9998 - val_loss: 0.1905 - val_accuracy: 0.9569 - lr: 2.8922e-05\n",
            "Epoch 73/300\n",
            "149/149 [==============================] - 18s 114ms/step - loss: 3.9563e-04 - accuracy: 1.0000 - val_loss: 0.1930 - val_accuracy: 0.9578 - lr: 2.7512e-05\n",
            "Epoch 74/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 3.4660e-04 - accuracy: 1.0000 - val_loss: 0.1795 - val_accuracy: 0.9611 - lr: 2.6170e-05\n",
            "Epoch 75/300\n",
            "149/149 [==============================] - 18s 114ms/step - loss: 2.5750e-04 - accuracy: 1.0000 - val_loss: 0.1730 - val_accuracy: 0.9654 - lr: 2.4894e-05\n",
            "Epoch 76/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 9.4955e-05 - accuracy: 1.0000 - val_loss: 0.1670 - val_accuracy: 0.9628 - lr: 2.3680e-05\n",
            "Epoch 77/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 1.3356e-04 - accuracy: 1.0000 - val_loss: 0.1660 - val_accuracy: 0.9637 - lr: 2.2525e-05\n",
            "Epoch 78/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 3.8187e-04 - accuracy: 1.0000 - val_loss: 0.1651 - val_accuracy: 0.9671 - lr: 2.1426e-05\n",
            "Epoch 79/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 3.8189e-04 - accuracy: 1.0000 - val_loss: 0.1668 - val_accuracy: 0.9679 - lr: 2.0381e-05\n",
            "Epoch 80/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 9.4965e-04 - accuracy: 0.9998 - val_loss: 0.1992 - val_accuracy: 0.9586 - lr: 1.9387e-05\n",
            "Epoch 81/300\n",
            "149/149 [==============================] - 18s 114ms/step - loss: 4.0374e-04 - accuracy: 0.9998 - val_loss: 0.1925 - val_accuracy: 0.9578 - lr: 1.8442e-05\n",
            "Epoch 82/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 8.3401e-04 - accuracy: 0.9996 - val_loss: 0.1762 - val_accuracy: 0.9595 - lr: 1.7542e-05\n",
            "Epoch 83/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 7.5617e-04 - accuracy: 0.9996 - val_loss: 0.1712 - val_accuracy: 0.9628 - lr: 1.6687e-05\n",
            "Epoch 84/300\n",
            "149/149 [==============================] - 18s 113ms/step - loss: 7.6551e-04 - accuracy: 0.9998 - val_loss: 0.1694 - val_accuracy: 0.9586 - lr: 1.5873e-05\n",
            "Epoch 85/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 2.6117e-04 - accuracy: 1.0000 - val_loss: 0.1691 - val_accuracy: 0.9603 - lr: 1.5099e-05\n",
            "Epoch 86/300\n",
            "149/149 [==============================] - 18s 113ms/step - loss: 5.8043e-04 - accuracy: 0.9998 - val_loss: 0.1612 - val_accuracy: 0.9628 - lr: 1.4362e-05\n",
            "Epoch 87/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 1.7587e-04 - accuracy: 1.0000 - val_loss: 0.1548 - val_accuracy: 0.9654 - lr: 1.3662e-05\n",
            "Epoch 88/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 1.5455e-04 - accuracy: 1.0000 - val_loss: 0.1546 - val_accuracy: 0.9662 - lr: 1.2996e-05\n",
            "Epoch 89/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 2.6553e-04 - accuracy: 1.0000 - val_loss: 0.1548 - val_accuracy: 0.9662 - lr: 1.2362e-05\n",
            "Epoch 90/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 1.2110e-04 - accuracy: 1.0000 - val_loss: 0.1575 - val_accuracy: 0.9628 - lr: 1.1759e-05\n",
            "Epoch 91/300\n",
            "149/149 [==============================] - 18s 113ms/step - loss: 1.2152e-04 - accuracy: 1.0000 - val_loss: 0.1564 - val_accuracy: 0.9628 - lr: 1.1185e-05\n",
            "Epoch 92/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 1.0486e-04 - accuracy: 1.0000 - val_loss: 0.1560 - val_accuracy: 0.9654 - lr: 1.0640e-05\n",
            "Epoch 93/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 2.1236e-04 - accuracy: 1.0000 - val_loss: 0.1576 - val_accuracy: 0.9645 - lr: 1.0121e-05\n",
            "Epoch 94/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 3.9861e-04 - accuracy: 0.9998 - val_loss: 0.1573 - val_accuracy: 0.9645 - lr: 9.6274e-06\n",
            "Epoch 95/300\n",
            "149/149 [==============================] - 18s 113ms/step - loss: 6.2048e-05 - accuracy: 1.0000 - val_loss: 0.1580 - val_accuracy: 0.9671 - lr: 9.1578e-06\n",
            "Epoch 96/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 1.8387e-04 - accuracy: 1.0000 - val_loss: 0.1582 - val_accuracy: 0.9671 - lr: 8.7112e-06\n",
            "Epoch 97/300\n",
            "149/149 [==============================] - 18s 113ms/step - loss: 1.2106e-04 - accuracy: 1.0000 - val_loss: 0.1579 - val_accuracy: 0.9679 - lr: 8.2864e-06\n",
            "Epoch 98/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 5.8359e-05 - accuracy: 1.0000 - val_loss: 0.1577 - val_accuracy: 0.9688 - lr: 7.8822e-06\n",
            "Epoch 99/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 5.7385e-05 - accuracy: 1.0000 - val_loss: 0.1572 - val_accuracy: 0.9688 - lr: 7.4978e-06\n",
            "Epoch 100/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 2.5455e-04 - accuracy: 0.9998 - val_loss: 0.1569 - val_accuracy: 0.9671 - lr: 7.1321e-06\n",
            "Epoch 101/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 1.1859e-04 - accuracy: 1.0000 - val_loss: 0.1526 - val_accuracy: 0.9654 - lr: 6.7843e-06\n",
            "Epoch 102/300\n",
            "149/149 [==============================] - 18s 113ms/step - loss: 1.7299e-04 - accuracy: 1.0000 - val_loss: 0.1524 - val_accuracy: 0.9662 - lr: 6.4534e-06\n",
            "Epoch 103/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 1.0290e-04 - accuracy: 1.0000 - val_loss: 0.1523 - val_accuracy: 0.9671 - lr: 6.1387e-06\n",
            "Epoch 104/300\n",
            "149/149 [==============================] - 18s 113ms/step - loss: 1.1330e-04 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9671 - lr: 5.8393e-06\n",
            "Epoch 105/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 5.3683e-05 - accuracy: 1.0000 - val_loss: 0.1526 - val_accuracy: 0.9679 - lr: 5.5545e-06\n",
            "Epoch 106/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 7.4914e-05 - accuracy: 1.0000 - val_loss: 0.1526 - val_accuracy: 0.9679 - lr: 5.2836e-06\n",
            "Epoch 107/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 8.6212e-05 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9679 - lr: 5.0259e-06\n",
            "Epoch 108/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 8.8519e-05 - accuracy: 1.0000 - val_loss: 0.1544 - val_accuracy: 0.9679 - lr: 4.7808e-06\n",
            "Epoch 109/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 1.0929e-04 - accuracy: 1.0000 - val_loss: 0.1537 - val_accuracy: 0.9679 - lr: 4.5477e-06\n",
            "Epoch 110/300\n",
            "149/149 [==============================] - 18s 113ms/step - loss: 1.4822e-04 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9688 - lr: 4.3259e-06\n",
            "Epoch 111/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 6.8158e-04 - accuracy: 0.9998 - val_loss: 0.1545 - val_accuracy: 0.9679 - lr: 4.1149e-06\n",
            "Epoch 112/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 5.2445e-05 - accuracy: 1.0000 - val_loss: 0.1527 - val_accuracy: 0.9688 - lr: 3.9142e-06\n",
            "Epoch 113/300\n",
            "149/149 [==============================] - 18s 115ms/step - loss: 1.0655e-04 - accuracy: 1.0000 - val_loss: 0.1532 - val_accuracy: 0.9688 - lr: 3.7233e-06\n",
            "Epoch 114/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 6.3637e-05 - accuracy: 1.0000 - val_loss: 0.1538 - val_accuracy: 0.9688 - lr: 3.5417e-06\n",
            "Epoch 115/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 9.5582e-05 - accuracy: 1.0000 - val_loss: 0.1525 - val_accuracy: 0.9688 - lr: 3.3690e-06\n",
            "Epoch 116/300\n",
            "149/149 [==============================] - 18s 114ms/step - loss: 9.1591e-05 - accuracy: 1.0000 - val_loss: 0.1515 - val_accuracy: 0.9688 - lr: 3.2047e-06\n",
            "Epoch 117/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 4.7183e-05 - accuracy: 1.0000 - val_loss: 0.1525 - val_accuracy: 0.9696 - lr: 3.0484e-06\n",
            "Epoch 118/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 6.2011e-05 - accuracy: 1.0000 - val_loss: 0.1529 - val_accuracy: 0.9688 - lr: 2.8997e-06\n",
            "Epoch 119/300\n",
            "149/149 [==============================] - 18s 115ms/step - loss: 6.7599e-05 - accuracy: 1.0000 - val_loss: 0.1527 - val_accuracy: 0.9688 - lr: 2.7583e-06\n",
            "Epoch 120/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 7.4110e-05 - accuracy: 1.0000 - val_loss: 0.1534 - val_accuracy: 0.9688 - lr: 2.6238e-06\n",
            "Epoch 121/300\n",
            "149/149 [==============================] - 18s 114ms/step - loss: 4.8080e-05 - accuracy: 1.0000 - val_loss: 0.1529 - val_accuracy: 0.9688 - lr: 2.4958e-06\n",
            "Epoch 122/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 5.8687e-05 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9688 - lr: 2.3741e-06\n",
            "Epoch 123/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 9.8349e-05 - accuracy: 1.0000 - val_loss: 0.1525 - val_accuracy: 0.9679 - lr: 2.2583e-06\n",
            "Epoch 124/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 5.0654e-05 - accuracy: 1.0000 - val_loss: 0.1526 - val_accuracy: 0.9679 - lr: 2.1482e-06\n",
            "Epoch 125/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 4.7442e-05 - accuracy: 1.0000 - val_loss: 0.1523 - val_accuracy: 0.9679 - lr: 2.0434e-06\n",
            "Epoch 126/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 5.8947e-05 - accuracy: 1.0000 - val_loss: 0.1521 - val_accuracy: 0.9679 - lr: 1.9437e-06\n",
            "Epoch 127/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 1.2609e-04 - accuracy: 1.0000 - val_loss: 0.1527 - val_accuracy: 0.9679 - lr: 1.8489e-06\n",
            "Epoch 128/300\n",
            "149/149 [==============================] - 18s 114ms/step - loss: 1.4853e-04 - accuracy: 1.0000 - val_loss: 0.1527 - val_accuracy: 0.9679 - lr: 1.7588e-06\n",
            "Epoch 129/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 4.2519e-05 - accuracy: 1.0000 - val_loss: 0.1507 - val_accuracy: 0.9679 - lr: 1.6730e-06\n",
            "Epoch 130/300\n",
            "149/149 [==============================] - 18s 114ms/step - loss: 5.3312e-05 - accuracy: 1.0000 - val_loss: 0.1505 - val_accuracy: 0.9688 - lr: 1.5914e-06\n",
            "Epoch 131/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 6.2606e-04 - accuracy: 0.9998 - val_loss: 0.1517 - val_accuracy: 0.9688 - lr: 1.5138e-06\n",
            "Epoch 132/300\n",
            "149/149 [==============================] - 18s 114ms/step - loss: 5.7840e-05 - accuracy: 1.0000 - val_loss: 0.1519 - val_accuracy: 0.9696 - lr: 1.4400e-06\n",
            "Epoch 133/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 8.1381e-05 - accuracy: 1.0000 - val_loss: 0.1522 - val_accuracy: 0.9688 - lr: 1.3697e-06\n",
            "Epoch 134/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 4.5874e-05 - accuracy: 1.0000 - val_loss: 0.1527 - val_accuracy: 0.9688 - lr: 1.3029e-06\n",
            "Epoch 135/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 7.1638e-05 - accuracy: 1.0000 - val_loss: 0.1529 - val_accuracy: 0.9696 - lr: 1.2394e-06\n",
            "Epoch 136/300\n",
            "149/149 [==============================] - 18s 114ms/step - loss: 2.6866e-04 - accuracy: 1.0000 - val_loss: 0.1525 - val_accuracy: 0.9679 - lr: 1.1789e-06\n",
            "Epoch 137/300\n",
            "149/149 [==============================] - 18s 114ms/step - loss: 4.8758e-05 - accuracy: 1.0000 - val_loss: 0.1526 - val_accuracy: 0.9679 - lr: 1.1214e-06\n",
            "Epoch 138/300\n",
            "149/149 [==============================] - 18s 113ms/step - loss: 5.7801e-05 - accuracy: 1.0000 - val_loss: 0.1539 - val_accuracy: 0.9679 - lr: 1.0667e-06\n",
            "Epoch 139/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 1.3507e-04 - accuracy: 1.0000 - val_loss: 0.1536 - val_accuracy: 0.9679 - lr: 1.0147e-06\n",
            "Epoch 140/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 7.3255e-05 - accuracy: 1.0000 - val_loss: 0.1528 - val_accuracy: 0.9679 - lr: 9.6523e-07\n",
            "Epoch 141/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 9.7239e-05 - accuracy: 1.0000 - val_loss: 0.1527 - val_accuracy: 0.9696 - lr: 9.1816e-07\n",
            "Epoch 142/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 3.5541e-05 - accuracy: 1.0000 - val_loss: 0.1527 - val_accuracy: 0.9688 - lr: 8.7338e-07\n",
            "Epoch 143/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 5.4649e-05 - accuracy: 1.0000 - val_loss: 0.1535 - val_accuracy: 0.9671 - lr: 8.3078e-07\n",
            "Epoch 144/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 5.9902e-05 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9679 - lr: 7.9026e-07\n",
            "Epoch 145/300\n",
            "149/149 [==============================] - 18s 113ms/step - loss: 3.8902e-05 - accuracy: 1.0000 - val_loss: 0.1527 - val_accuracy: 0.9696 - lr: 7.5172e-07\n",
            "Epoch 146/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 4.5324e-05 - accuracy: 1.0000 - val_loss: 0.1532 - val_accuracy: 0.9679 - lr: 7.1506e-07\n",
            "Epoch 147/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 8.5066e-05 - accuracy: 1.0000 - val_loss: 0.1521 - val_accuracy: 0.9679 - lr: 6.8019e-07\n",
            "Epoch 148/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 1.2624e-04 - accuracy: 1.0000 - val_loss: 0.1521 - val_accuracy: 0.9688 - lr: 6.4701e-07\n",
            "Epoch 149/300\n",
            "149/149 [==============================] - 18s 113ms/step - loss: 6.6857e-05 - accuracy: 1.0000 - val_loss: 0.1525 - val_accuracy: 0.9696 - lr: 6.1546e-07\n",
            "Epoch 150/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 4.3677e-05 - accuracy: 1.0000 - val_loss: 0.1526 - val_accuracy: 0.9688 - lr: 5.8544e-07\n",
            "Epoch 151/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 1.6000e-04 - accuracy: 1.0000 - val_loss: 0.1528 - val_accuracy: 0.9696 - lr: 5.5689e-07\n",
            "Epoch 152/300\n",
            "149/149 [==============================] - 18s 113ms/step - loss: 5.7916e-05 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9688 - lr: 5.2973e-07\n",
            "Epoch 153/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 7.5463e-05 - accuracy: 1.0000 - val_loss: 0.1527 - val_accuracy: 0.9688 - lr: 5.0389e-07\n",
            "Epoch 154/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 4.9829e-05 - accuracy: 1.0000 - val_loss: 0.1525 - val_accuracy: 0.9688 - lr: 4.7932e-07\n",
            "Epoch 155/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 1.1901e-04 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9679 - lr: 4.5594e-07\n",
            "Epoch 156/300\n",
            "149/149 [==============================] - 18s 114ms/step - loss: 6.7253e-05 - accuracy: 1.0000 - val_loss: 0.1539 - val_accuracy: 0.9679 - lr: 4.3371e-07\n",
            "Epoch 157/300\n",
            "149/149 [==============================] - 18s 114ms/step - loss: 3.8064e-05 - accuracy: 1.0000 - val_loss: 0.1539 - val_accuracy: 0.9679 - lr: 4.1255e-07\n",
            "Epoch 158/300\n",
            "149/149 [==============================] - 18s 113ms/step - loss: 9.1396e-05 - accuracy: 1.0000 - val_loss: 0.1538 - val_accuracy: 0.9679 - lr: 3.9243e-07\n",
            "Epoch 159/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 7.1709e-05 - accuracy: 1.0000 - val_loss: 0.1534 - val_accuracy: 0.9679 - lr: 3.7329e-07\n",
            "Epoch 160/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 5.5925e-05 - accuracy: 1.0000 - val_loss: 0.1534 - val_accuracy: 0.9679 - lr: 3.5509e-07\n",
            "Epoch 161/300\n",
            "149/149 [==============================] - 18s 114ms/step - loss: 1.1549e-04 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9679 - lr: 3.3777e-07\n",
            "Epoch 162/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 4.7199e-05 - accuracy: 1.0000 - val_loss: 0.1539 - val_accuracy: 0.9671 - lr: 3.2130e-07\n",
            "Epoch 163/300\n",
            "149/149 [==============================] - 18s 113ms/step - loss: 5.9425e-05 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9679 - lr: 3.0563e-07\n",
            "Epoch 164/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 6.4379e-05 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9688 - lr: 2.9072e-07\n",
            "Epoch 165/300\n",
            "149/149 [==============================] - 18s 114ms/step - loss: 2.7708e-04 - accuracy: 1.0000 - val_loss: 0.1539 - val_accuracy: 0.9671 - lr: 2.7654e-07\n",
            "Epoch 166/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 8.4472e-05 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9679 - lr: 2.6306e-07\n",
            "Epoch 167/300\n",
            "149/149 [==============================] - 18s 114ms/step - loss: 3.4276e-05 - accuracy: 1.0000 - val_loss: 0.1534 - val_accuracy: 0.9679 - lr: 2.5023e-07\n",
            "Epoch 168/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 5.0680e-05 - accuracy: 1.0000 - val_loss: 0.1537 - val_accuracy: 0.9679 - lr: 2.3802e-07\n",
            "Epoch 169/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 5.8395e-05 - accuracy: 1.0000 - val_loss: 0.1528 - val_accuracy: 0.9688 - lr: 2.2641e-07\n",
            "Epoch 170/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 4.1585e-05 - accuracy: 1.0000 - val_loss: 0.1527 - val_accuracy: 0.9688 - lr: 2.1537e-07\n",
            "Epoch 171/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 4.8066e-05 - accuracy: 1.0000 - val_loss: 0.1537 - val_accuracy: 0.9679 - lr: 2.0487e-07\n",
            "Epoch 172/300\n",
            "149/149 [==============================] - 18s 113ms/step - loss: 2.1744e-04 - accuracy: 1.0000 - val_loss: 0.1536 - val_accuracy: 0.9688 - lr: 1.9488e-07\n",
            "Epoch 173/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 1.1879e-04 - accuracy: 1.0000 - val_loss: 0.1536 - val_accuracy: 0.9679 - lr: 1.8537e-07\n",
            "Epoch 174/300\n",
            "149/149 [==============================] - 18s 114ms/step - loss: 4.6389e-05 - accuracy: 1.0000 - val_loss: 0.1538 - val_accuracy: 0.9679 - lr: 1.7633e-07\n",
            "Epoch 175/300\n",
            "149/149 [==============================] - 18s 113ms/step - loss: 1.1991e-04 - accuracy: 1.0000 - val_loss: 0.1539 - val_accuracy: 0.9679 - lr: 1.6773e-07\n",
            "Epoch 176/300\n",
            "149/149 [==============================] - 18s 113ms/step - loss: 7.8302e-05 - accuracy: 1.0000 - val_loss: 0.1537 - val_accuracy: 0.9688 - lr: 1.5955e-07\n",
            "Epoch 177/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 6.3245e-05 - accuracy: 1.0000 - val_loss: 0.1535 - val_accuracy: 0.9679 - lr: 1.5177e-07\n",
            "Epoch 178/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 3.6619e-05 - accuracy: 1.0000 - val_loss: 0.1536 - val_accuracy: 0.9679 - lr: 1.4437e-07\n",
            "Epoch 179/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 4.1497e-05 - accuracy: 1.0000 - val_loss: 0.1540 - val_accuracy: 0.9688 - lr: 1.3733e-07\n",
            "Epoch 180/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 1.6363e-04 - accuracy: 1.0000 - val_loss: 0.1546 - val_accuracy: 0.9679 - lr: 1.3063e-07\n",
            "Epoch 181/300\n",
            "149/149 [==============================] - 18s 113ms/step - loss: 7.7049e-05 - accuracy: 1.0000 - val_loss: 0.1537 - val_accuracy: 0.9688 - lr: 1.2426e-07\n",
            "Epoch 182/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 4.6872e-05 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9688 - lr: 1.1820e-07\n",
            "Epoch 183/300\n",
            "149/149 [==============================] - 18s 113ms/step - loss: 1.5963e-04 - accuracy: 1.0000 - val_loss: 0.1540 - val_accuracy: 0.9671 - lr: 1.1243e-07\n",
            "Epoch 184/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 4.0173e-05 - accuracy: 1.0000 - val_loss: 0.1526 - val_accuracy: 0.9688 - lr: 1.0695e-07\n",
            "Epoch 185/300\n",
            "149/149 [==============================] - 18s 114ms/step - loss: 6.4541e-05 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9688 - lr: 1.0173e-07\n",
            "Epoch 186/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 1.3891e-04 - accuracy: 1.0000 - val_loss: 0.1527 - val_accuracy: 0.9696 - lr: 9.6773e-08\n",
            "Epoch 187/300\n",
            "149/149 [==============================] - 18s 113ms/step - loss: 5.1938e-05 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9688 - lr: 9.2053e-08\n",
            "Epoch 188/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 5.4303e-05 - accuracy: 1.0000 - val_loss: 0.1535 - val_accuracy: 0.9688 - lr: 8.7564e-08\n",
            "Epoch 189/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 7.8207e-05 - accuracy: 1.0000 - val_loss: 0.1534 - val_accuracy: 0.9688 - lr: 8.3293e-08\n",
            "Epoch 190/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 1.4692e-04 - accuracy: 1.0000 - val_loss: 0.1535 - val_accuracy: 0.9679 - lr: 7.9231e-08\n",
            "Epoch 191/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 1.6402e-04 - accuracy: 1.0000 - val_loss: 0.1541 - val_accuracy: 0.9679 - lr: 7.5367e-08\n",
            "Epoch 192/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 4.7987e-05 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9688 - lr: 7.1691e-08\n",
            "Epoch 193/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 8.2662e-05 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9688 - lr: 6.8195e-08\n",
            "Epoch 194/300\n",
            "149/149 [==============================] - 18s 113ms/step - loss: 3.7902e-05 - accuracy: 1.0000 - val_loss: 0.1532 - val_accuracy: 0.9688 - lr: 6.4869e-08\n",
            "Epoch 195/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 5.2226e-05 - accuracy: 1.0000 - val_loss: 0.1529 - val_accuracy: 0.9688 - lr: 6.1705e-08\n",
            "Epoch 196/300\n",
            "149/149 [==============================] - 18s 113ms/step - loss: 3.7276e-04 - accuracy: 0.9998 - val_loss: 0.1529 - val_accuracy: 0.9696 - lr: 5.8696e-08\n",
            "Epoch 197/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 6.5932e-05 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9688 - lr: 5.5833e-08\n",
            "Epoch 198/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 6.8707e-05 - accuracy: 1.0000 - val_loss: 0.1530 - val_accuracy: 0.9688 - lr: 5.3110e-08\n",
            "Epoch 199/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 9.7578e-05 - accuracy: 1.0000 - val_loss: 0.1537 - val_accuracy: 0.9688 - lr: 5.0520e-08\n",
            "Epoch 200/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 6.2845e-05 - accuracy: 1.0000 - val_loss: 0.1536 - val_accuracy: 0.9688 - lr: 4.8056e-08\n",
            "Epoch 201/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 1.0620e-04 - accuracy: 1.0000 - val_loss: 0.1536 - val_accuracy: 0.9688 - lr: 4.5712e-08\n",
            "Epoch 202/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 3.9013e-05 - accuracy: 1.0000 - val_loss: 0.1527 - val_accuracy: 0.9688 - lr: 4.3483e-08\n",
            "Epoch 203/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 1.1187e-04 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9679 - lr: 4.1362e-08\n",
            "Epoch 204/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 0.0055 - accuracy: 0.9996 - val_loss: 0.1534 - val_accuracy: 0.9696 - lr: 3.9345e-08\n",
            "Epoch 205/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 2.4755e-04 - accuracy: 0.9998 - val_loss: 0.1526 - val_accuracy: 0.9688 - lr: 3.7426e-08\n",
            "Epoch 206/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 5.9537e-05 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9688 - lr: 3.5601e-08\n",
            "Epoch 207/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 2.8726e-05 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9688 - lr: 3.3865e-08\n",
            "Epoch 208/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 4.6785e-05 - accuracy: 1.0000 - val_loss: 0.1534 - val_accuracy: 0.9688 - lr: 3.2213e-08\n",
            "Epoch 209/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 5.9208e-05 - accuracy: 1.0000 - val_loss: 0.1530 - val_accuracy: 0.9688 - lr: 3.0642e-08\n",
            "Epoch 210/300\n",
            "149/149 [==============================] - 18s 115ms/step - loss: 7.3598e-05 - accuracy: 1.0000 - val_loss: 0.1530 - val_accuracy: 0.9688 - lr: 2.9147e-08\n",
            "Epoch 211/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 6.8609e-05 - accuracy: 1.0000 - val_loss: 0.1535 - val_accuracy: 0.9688 - lr: 2.7726e-08\n",
            "Epoch 212/300\n",
            "149/149 [==============================] - 17s 110ms/step - loss: 1.3167e-04 - accuracy: 1.0000 - val_loss: 0.1535 - val_accuracy: 0.9679 - lr: 2.6374e-08\n",
            "Epoch 213/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 3.4422e-05 - accuracy: 1.0000 - val_loss: 0.1529 - val_accuracy: 0.9696 - lr: 2.5087e-08\n",
            "Epoch 214/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 4.6181e-05 - accuracy: 1.0000 - val_loss: 0.1529 - val_accuracy: 0.9688 - lr: 2.3864e-08\n",
            "Epoch 215/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 7.2059e-05 - accuracy: 1.0000 - val_loss: 0.1534 - val_accuracy: 0.9688 - lr: 2.2700e-08\n",
            "Epoch 216/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 5.3881e-05 - accuracy: 1.0000 - val_loss: 0.1535 - val_accuracy: 0.9696 - lr: 2.1593e-08\n",
            "Epoch 217/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 1.7838e-04 - accuracy: 1.0000 - val_loss: 0.1536 - val_accuracy: 0.9679 - lr: 2.0540e-08\n",
            "Epoch 218/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 3.9916e-05 - accuracy: 1.0000 - val_loss: 0.1535 - val_accuracy: 0.9688 - lr: 1.9538e-08\n",
            "Epoch 219/300\n",
            "149/149 [==============================] - 17s 110ms/step - loss: 7.1334e-05 - accuracy: 1.0000 - val_loss: 0.1530 - val_accuracy: 0.9688 - lr: 1.8585e-08\n",
            "Epoch 220/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 5.0362e-05 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9688 - lr: 1.7679e-08\n",
            "Epoch 221/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 8.3189e-05 - accuracy: 1.0000 - val_loss: 0.1532 - val_accuracy: 0.9688 - lr: 1.6817e-08\n",
            "Epoch 222/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 4.6935e-05 - accuracy: 1.0000 - val_loss: 0.1530 - val_accuracy: 0.9688 - lr: 1.5996e-08\n",
            "Epoch 223/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 6.7695e-05 - accuracy: 1.0000 - val_loss: 0.1532 - val_accuracy: 0.9688 - lr: 1.5216e-08\n",
            "Epoch 224/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 5.6667e-05 - accuracy: 1.0000 - val_loss: 0.1535 - val_accuracy: 0.9679 - lr: 1.4474e-08\n",
            "Epoch 225/300\n",
            "149/149 [==============================] - 17s 110ms/step - loss: 1.0066e-04 - accuracy: 1.0000 - val_loss: 0.1532 - val_accuracy: 0.9688 - lr: 1.3768e-08\n",
            "Epoch 226/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 6.8928e-05 - accuracy: 1.0000 - val_loss: 0.1525 - val_accuracy: 0.9688 - lr: 1.3097e-08\n",
            "Epoch 227/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 1.5315e-04 - accuracy: 1.0000 - val_loss: 0.1526 - val_accuracy: 0.9688 - lr: 1.2458e-08\n",
            "Epoch 228/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 8.3130e-05 - accuracy: 1.0000 - val_loss: 0.1535 - val_accuracy: 0.9688 - lr: 1.1850e-08\n",
            "Epoch 229/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 8.4518e-05 - accuracy: 1.0000 - val_loss: 0.1532 - val_accuracy: 0.9688 - lr: 1.1273e-08\n",
            "Epoch 230/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 3.1434e-05 - accuracy: 1.0000 - val_loss: 0.1536 - val_accuracy: 0.9688 - lr: 1.0723e-08\n",
            "Epoch 231/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 6.2841e-05 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9688 - lr: 1.0200e-08\n",
            "Epoch 232/300\n",
            "149/149 [==============================] - 17s 110ms/step - loss: 9.7543e-05 - accuracy: 1.0000 - val_loss: 0.1539 - val_accuracy: 0.9679 - lr: 9.7024e-09\n",
            "Epoch 233/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 4.6888e-05 - accuracy: 1.0000 - val_loss: 0.1536 - val_accuracy: 0.9688 - lr: 9.2292e-09\n",
            "Epoch 234/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 4.4573e-05 - accuracy: 1.0000 - val_loss: 0.1535 - val_accuracy: 0.9688 - lr: 8.7791e-09\n",
            "Epoch 235/300\n",
            "149/149 [==============================] - 17s 110ms/step - loss: 4.1788e-05 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9688 - lr: 8.3509e-09\n",
            "Epoch 236/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 6.6994e-05 - accuracy: 1.0000 - val_loss: 0.1536 - val_accuracy: 0.9688 - lr: 7.9436e-09\n",
            "Epoch 237/300\n",
            "149/149 [==============================] - 17s 110ms/step - loss: 2.6579e-04 - accuracy: 0.9998 - val_loss: 0.1528 - val_accuracy: 0.9688 - lr: 7.5562e-09\n",
            "Epoch 238/300\n",
            "149/149 [==============================] - 17s 110ms/step - loss: 4.7446e-05 - accuracy: 1.0000 - val_loss: 0.1534 - val_accuracy: 0.9688 - lr: 7.1877e-09\n",
            "Epoch 239/300\n",
            "149/149 [==============================] - 17s 110ms/step - loss: 6.0675e-05 - accuracy: 1.0000 - val_loss: 0.1534 - val_accuracy: 0.9688 - lr: 6.8371e-09\n",
            "Epoch 240/300\n",
            "149/149 [==============================] - 17s 110ms/step - loss: 4.1310e-05 - accuracy: 1.0000 - val_loss: 0.1534 - val_accuracy: 0.9688 - lr: 6.5037e-09\n",
            "Epoch 241/300\n",
            "149/149 [==============================] - 17s 113ms/step - loss: 1.0021e-04 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9688 - lr: 6.1865e-09\n",
            "Epoch 242/300\n",
            "149/149 [==============================] - 17s 110ms/step - loss: 4.1273e-04 - accuracy: 0.9998 - val_loss: 0.1535 - val_accuracy: 0.9688 - lr: 5.8848e-09\n",
            "Epoch 243/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 4.5715e-04 - accuracy: 0.9998 - val_loss: 0.1529 - val_accuracy: 0.9688 - lr: 5.5978e-09\n",
            "Epoch 244/300\n",
            "149/149 [==============================] - 17s 110ms/step - loss: 6.1495e-05 - accuracy: 1.0000 - val_loss: 0.1530 - val_accuracy: 0.9688 - lr: 5.3248e-09\n",
            "Epoch 245/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 4.4751e-05 - accuracy: 1.0000 - val_loss: 0.1532 - val_accuracy: 0.9688 - lr: 5.0651e-09\n",
            "Epoch 246/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 5.0425e-05 - accuracy: 1.0000 - val_loss: 0.1529 - val_accuracy: 0.9688 - lr: 4.8181e-09\n",
            "Epoch 247/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 4.9424e-05 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9688 - lr: 4.5831e-09\n",
            "Epoch 248/300\n",
            "149/149 [==============================] - 17s 110ms/step - loss: 7.0863e-05 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9688 - lr: 4.3596e-09\n",
            "Epoch 249/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 6.9839e-05 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9688 - lr: 4.1469e-09\n",
            "Epoch 250/300\n",
            "149/149 [==============================] - 17s 110ms/step - loss: 5.1340e-05 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9679 - lr: 3.9447e-09\n",
            "Epoch 251/300\n",
            "149/149 [==============================] - 17s 110ms/step - loss: 4.5480e-05 - accuracy: 1.0000 - val_loss: 0.1535 - val_accuracy: 0.9688 - lr: 3.7523e-09\n",
            "Epoch 252/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 4.8750e-05 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9679 - lr: 3.5693e-09\n",
            "Epoch 253/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 5.7740e-05 - accuracy: 1.0000 - val_loss: 0.1534 - val_accuracy: 0.9688 - lr: 3.3952e-09\n",
            "Epoch 254/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 4.0769e-05 - accuracy: 1.0000 - val_loss: 0.1535 - val_accuracy: 0.9688 - lr: 3.2296e-09\n",
            "Epoch 255/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 7.2373e-05 - accuracy: 1.0000 - val_loss: 0.1539 - val_accuracy: 0.9679 - lr: 3.0721e-09\n",
            "Epoch 256/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 0.0065 - accuracy: 0.9998 - val_loss: 0.1533 - val_accuracy: 0.9696 - lr: 2.9223e-09\n",
            "Epoch 257/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 4.7596e-05 - accuracy: 1.0000 - val_loss: 0.1535 - val_accuracy: 0.9688 - lr: 2.7798e-09\n",
            "Epoch 258/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 7.3459e-05 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9688 - lr: 2.6442e-09\n",
            "Epoch 259/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 3.2764e-05 - accuracy: 1.0000 - val_loss: 0.1527 - val_accuracy: 0.9688 - lr: 2.5152e-09\n",
            "Epoch 260/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 3.9419e-05 - accuracy: 1.0000 - val_loss: 0.1525 - val_accuracy: 0.9688 - lr: 2.3926e-09\n",
            "Epoch 261/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 5.8344e-05 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9679 - lr: 2.2759e-09\n",
            "Epoch 262/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 5.0697e-05 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9688 - lr: 2.1649e-09\n",
            "Epoch 263/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 5.1517e-05 - accuracy: 1.0000 - val_loss: 0.1530 - val_accuracy: 0.9688 - lr: 2.0593e-09\n",
            "Epoch 264/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 6.5304e-05 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9688 - lr: 1.9589e-09\n",
            "Epoch 265/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 0.0064 - accuracy: 0.9994 - val_loss: 0.1527 - val_accuracy: 0.9704 - lr: 1.8633e-09\n",
            "Epoch 266/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 4.5184e-05 - accuracy: 1.0000 - val_loss: 0.1530 - val_accuracy: 0.9688 - lr: 1.7725e-09\n",
            "Epoch 267/300\n",
            "149/149 [==============================] - 17s 110ms/step - loss: 4.6477e-05 - accuracy: 1.0000 - val_loss: 0.1528 - val_accuracy: 0.9688 - lr: 1.6860e-09\n",
            "Epoch 268/300\n",
            "149/149 [==============================] - 19s 122ms/step - loss: 4.1316e-05 - accuracy: 1.0000 - val_loss: 0.1529 - val_accuracy: 0.9688 - lr: 1.6038e-09\n",
            "Epoch 269/300\n",
            "149/149 [==============================] - 17s 110ms/step - loss: 1.0781e-04 - accuracy: 1.0000 - val_loss: 0.1530 - val_accuracy: 0.9688 - lr: 1.5256e-09\n",
            "Epoch 270/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 1.6642e-04 - accuracy: 1.0000 - val_loss: 0.1530 - val_accuracy: 0.9688 - lr: 1.4512e-09\n",
            "Epoch 271/300\n",
            "149/149 [==============================] - 17s 110ms/step - loss: 4.9333e-05 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9688 - lr: 1.3804e-09\n",
            "Epoch 272/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 4.8117e-05 - accuracy: 1.0000 - val_loss: 0.1530 - val_accuracy: 0.9688 - lr: 1.3131e-09\n",
            "Epoch 273/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 5.2102e-05 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9679 - lr: 1.2490e-09\n",
            "Epoch 274/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 6.5979e-05 - accuracy: 1.0000 - val_loss: 0.1528 - val_accuracy: 0.9688 - lr: 1.1881e-09\n",
            "Epoch 275/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 2.9776e-04 - accuracy: 0.9998 - val_loss: 0.1534 - val_accuracy: 0.9688 - lr: 1.1302e-09\n",
            "Epoch 276/300\n",
            "149/149 [==============================] - 17s 110ms/step - loss: 3.1010e-05 - accuracy: 1.0000 - val_loss: 0.1538 - val_accuracy: 0.9679 - lr: 1.0751e-09\n",
            "Epoch 277/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 5.8575e-05 - accuracy: 1.0000 - val_loss: 0.1538 - val_accuracy: 0.9679 - lr: 1.0226e-09\n",
            "Epoch 278/300\n",
            "149/149 [==============================] - 17s 110ms/step - loss: 3.9644e-05 - accuracy: 1.0000 - val_loss: 0.1529 - val_accuracy: 0.9688 - lr: 9.7275e-10\n",
            "Epoch 279/300\n",
            "149/149 [==============================] - 17s 110ms/step - loss: 5.7705e-05 - accuracy: 1.0000 - val_loss: 0.1534 - val_accuracy: 0.9688 - lr: 9.2531e-10\n",
            "Epoch 280/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 5.1881e-05 - accuracy: 1.0000 - val_loss: 0.1527 - val_accuracy: 0.9688 - lr: 8.8018e-10\n",
            "Epoch 281/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 1.2148e-04 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9688 - lr: 8.3725e-10\n",
            "Epoch 282/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 6.2477e-05 - accuracy: 1.0000 - val_loss: 0.1537 - val_accuracy: 0.9679 - lr: 7.9642e-10\n",
            "Epoch 283/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 9.6690e-04 - accuracy: 0.9998 - val_loss: 0.1527 - val_accuracy: 0.9704 - lr: 7.5758e-10\n",
            "Epoch 284/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 6.0691e-05 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9688 - lr: 7.2063e-10\n",
            "Epoch 285/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 4.7072e-05 - accuracy: 1.0000 - val_loss: 0.1534 - val_accuracy: 0.9688 - lr: 6.8549e-10\n",
            "Epoch 286/300\n",
            "149/149 [==============================] - 20s 131ms/step - loss: 4.8094e-05 - accuracy: 1.0000 - val_loss: 0.1534 - val_accuracy: 0.9688 - lr: 6.5205e-10\n",
            "Epoch 287/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 5.3024e-05 - accuracy: 1.0000 - val_loss: 0.1530 - val_accuracy: 0.9688 - lr: 6.2025e-10\n",
            "Epoch 288/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 3.0818e-05 - accuracy: 1.0000 - val_loss: 0.1534 - val_accuracy: 0.9688 - lr: 5.9000e-10\n",
            "Epoch 289/300\n",
            "149/149 [==============================] - 17s 110ms/step - loss: 7.5367e-05 - accuracy: 1.0000 - val_loss: 0.1532 - val_accuracy: 0.9688 - lr: 5.6123e-10\n",
            "Epoch 290/300\n",
            "149/149 [==============================] - 17s 110ms/step - loss: 8.9280e-05 - accuracy: 1.0000 - val_loss: 0.1537 - val_accuracy: 0.9679 - lr: 5.3386e-10\n",
            "Epoch 291/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 4.8199e-05 - accuracy: 1.0000 - val_loss: 0.1532 - val_accuracy: 0.9688 - lr: 5.0782e-10\n",
            "Epoch 292/300\n",
            "149/149 [==============================] - 17s 110ms/step - loss: 9.9195e-05 - accuracy: 1.0000 - val_loss: 0.1540 - val_accuracy: 0.9679 - lr: 4.8305e-10\n",
            "Epoch 293/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 1.3188e-04 - accuracy: 1.0000 - val_loss: 0.1532 - val_accuracy: 0.9688 - lr: 4.5949e-10\n",
            "Epoch 294/300\n",
            "149/149 [==============================] - 17s 110ms/step - loss: 8.2737e-05 - accuracy: 1.0000 - val_loss: 0.1529 - val_accuracy: 0.9688 - lr: 4.3708e-10\n",
            "Epoch 295/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 9.4810e-05 - accuracy: 1.0000 - val_loss: 0.1530 - val_accuracy: 0.9688 - lr: 4.1577e-10\n",
            "Epoch 296/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 4.2855e-05 - accuracy: 1.0000 - val_loss: 0.1537 - val_accuracy: 0.9688 - lr: 3.9549e-10\n",
            "Epoch 297/300\n",
            "149/149 [==============================] - 17s 112ms/step - loss: 3.8355e-05 - accuracy: 1.0000 - val_loss: 0.1539 - val_accuracy: 0.9679 - lr: 3.7620e-10\n",
            "Epoch 298/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 4.8794e-05 - accuracy: 1.0000 - val_loss: 0.1539 - val_accuracy: 0.9679 - lr: 3.5785e-10\n",
            "Epoch 299/300\n",
            "149/149 [==============================] - 17s 110ms/step - loss: 5.2718e-05 - accuracy: 1.0000 - val_loss: 0.1534 - val_accuracy: 0.9688 - lr: 3.4040e-10\n",
            "Epoch 300/300\n",
            "149/149 [==============================] - 17s 111ms/step - loss: 2.7707e-05 - accuracy: 1.0000 - val_loss: 0.1532 - val_accuracy: 0.9688 - lr: 3.2380e-10\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "machine_shape": "hm",
      "collapsed_sections": [
        "b0z218uujo7d"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}